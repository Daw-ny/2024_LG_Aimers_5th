{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a48e6e",
   "metadata": {},
   "source": [
    "# 불량품 예측\n",
    "\n",
    "불량품을 예측하기 위해 다음과 같은 함수화 정리를 진행한다. 혼란을 막기 위해 모든 과정을 함수화 하기로 한다.  \n",
    "목차는 다음과 같다.\n",
    "\n",
    "- 1. Load packages & Data\n",
    "- 2. Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe380d",
   "metadata": {},
   "source": [
    "## Equip1 유의한 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5915364",
   "metadata": {},
   "source": [
    "'DISCHARGED SPEED OF RESIN Collect Result_Dam',  \n",
    "'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',  \n",
    "'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',  \n",
    "'Stage2 Circle1 Distance Speed Collect Result_Dam',  \n",
    "'THICKNESS 1 Collect Result_Dam',  \n",
    "'THICKNESS 2 Collect Result_Dam',  \n",
    "'THICKNESS 3 Collect Result_Dam',  \n",
    "'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',  \n",
    "'Dispense Volume(Stage3) Collect Result_Fill1',  \n",
    "'Stage2 Line diffent Distance Speed_Dam',  \n",
    "'round_1st_time',  \n",
    "'round_2nd_time'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733caab",
   "metadata": {},
   "source": [
    "## Equip2 유의한 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546610dc",
   "metadata": {},
   "source": [
    "'Model.Suffix_Dam',  \n",
    "'DISCHARGED SPEED OF RESIN Collect Result_Dam',  \n",
    "'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',  \n",
    "'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',  \n",
    "'Head Zero Position Y Collect Result_Dam',  \n",
    "'Stage2 Circle1 Distance Speed Collect Result_Dam',  \n",
    "'DISCHARGED SPEED OF RESIN Collect Result_Fill1',  \n",
    "'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',  \n",
    "'Dispense Volume(Stage3) Collect Result_Fill1',  \n",
    "'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',  \n",
    "'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',  \n",
    "'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',  \n",
    "'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1',  \n",
    "'Machine Tact time Collect Result_Fill1',  \n",
    "'CURE SPEED Collect Result_Fill2',  \n",
    "'CURE START POSITION Z Collect Result_Fill2',  \n",
    "'Stage2 Line diffent Distance Speed_Dam',  \n",
    "'round_1st_time',  \n",
    "'round_2nd_time',  \n",
    "'round_3rd_time',  \n",
    "'workorder_third'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab477ae",
   "metadata": {},
   "source": [
    "## 1. Load Packages & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e5c4af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "### ide packages\n",
    "import os\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "# sklearn preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    make_scorer,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    recall_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier, plot_metric\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# tuning\n",
    "import optuna\n",
    "\n",
    "# validation \n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import levene, ttest_ind\n",
    "from scipy.stats import bartlett\n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea357c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "load_dir = './data/'\n",
    "train = pd.read_csv(load_dir + \"train.csv\")\n",
    "test = pd.read_csv(load_dir + \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190d3439",
   "metadata": {},
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195e730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 스코어 지정하기\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1, average = 'binary')\n",
    "\n",
    "# 평가 매트릭 계산 결과 보여주기\n",
    "def get_clf_eval(y_test, y_pred=None):\n",
    "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
    "\n",
    "    print(\"오차행렬:\\n\", confusion)\n",
    "    print(\"\\n정확도: {:.4f}\".format(accuracy))\n",
    "    print(\"정밀도: {:.4f}\".format(precision))\n",
    "    print(\"재현율: {:.4f}\".format(recall))\n",
    "    print(\"F1: {:.4f}\".format(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1867a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 공정 맞춤형 위치 옮기기\n",
    "def move_data(data):\n",
    "    # divide\n",
    "    dam = data.filter(regex='_Dam')\n",
    "    fill1 = data.filter(regex='_Fill1')\n",
    "    fill2 = data.filter(regex='_Fill2')\n",
    "    autoclave = data.filter(regex='_AutoClave')\n",
    "    target = data['target']\n",
    "\n",
    "    # dam\n",
    "    dam = dam.dropna(axis=1, how='all')\n",
    "    dam = dam.drop(columns='HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam')\n",
    "    dam_mask = dam[dam['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].isin(['OK', np.nan])].iloc[:, 24:].shift(-1, axis = 1).values\n",
    "    dam.loc[dam['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].isin(['OK', np.nan]), dam.columns[24:]] = dam_mask\n",
    "    dam = dam.drop(columns='WorkMode Collect Result_Dam')\n",
    "\n",
    "    # fill1\n",
    "    fill1 = fill1.dropna(axis=1, how='all')\n",
    "    fill1 = fill1.drop(columns='HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1')\n",
    "    fill1_mask = fill1[fill1['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].isin(['OK', np.nan])].iloc[:, 14:].shift(-1, axis = 1).values\n",
    "    fill1.loc[fill1['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].isin(['OK', np.nan]), fill1.columns[14:]] = fill1_mask\n",
    "    fill1 = fill1.drop(columns='WorkMode Collect Result_Fill1')\n",
    "\n",
    "    # fill2\n",
    "    fill2 = fill2.dropna(axis=1, how='all')\n",
    "    fill2 = fill2.drop(columns='HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2')\n",
    "    fill2_mask = fill2[fill2['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].isin(['OK', np.nan])].iloc[:, 24:].shift(-1, axis = 1).values\n",
    "    fill2.loc[fill2['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].isin(['OK', np.nan]), fill2.columns[24:]] = fill2_mask\n",
    "    fill2 = fill2.drop(columns='WorkMode Collect Result_Fill2')\n",
    "\n",
    "    # CONCAT\n",
    "    data = pd.concat([dam, fill1, fill2, autoclave, target], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32fad315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dam, Fill1, Fill2에서 지정된 값이 다를 경우 Abnormal \n",
    "def inconsistant(data, columnname, iwantthiscolumnsname, is_train = True):\n",
    "    # 장비 번호가 다르면 불일치\n",
    "    if is_train:\n",
    "        cri = [\n",
    "            df_train[columnname + '_Dam'] != df_train[columnname + '_Fill1'],\n",
    "            df_train[columnname + '_Dam'] != df_train[columnname + '_Fill2'],\n",
    "            df_train[columnname + '_Fill1'] != df_train[columnname + '_Fill2'],\n",
    "            data[iwantthiscolumnsname] == 1\n",
    "        ]\n",
    "        \n",
    "    else:\n",
    "        cri = [\n",
    "            df_test[columnname + '_Dam'] != df_test[columnname + '_Fill1'],\n",
    "            df_test[columnname + '_Dam'] != df_test[columnname + '_Fill2'],\n",
    "            df_test[columnname + '_Fill1'] != df_test[columnname + '_Fill1'],\n",
    "            data[iwantthiscolumnsname] == 1\n",
    "        ]\n",
    "    con = [1, 1, 1, 1]\n",
    "\n",
    "    data[iwantthiscolumnsname] = np.select(cri, con, default = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804698ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 세팅\n",
    "def variable_setting(types, tr, te, cat_col):\n",
    "    train = tr.copy()\n",
    "    test = te.copy()\n",
    "    \n",
    "    if types == 'catboost':\n",
    "        dtype = 'string'  # 원하는 데이터 타입\n",
    "        for column in cat_col:\n",
    "            train[column] = train[column].astype(dtype)\n",
    "            test[column] = test[column].astype(dtype)\n",
    "\n",
    "        dtype = 'category'  # 원하는 데이터 타입\n",
    "        for column in cat_col:\n",
    "            train[column] = train[column].astype(dtype)\n",
    "            test[column] = test[column].astype(dtype)\n",
    "            \n",
    "    elif types == 'lightgbm':\n",
    "        dtype = 'float'  # 원하는 데이터 타입\n",
    "        for column in cat_col:\n",
    "            train[column] = train[column].astype(dtype)\n",
    "            test[column] = test[column].astype(dtype)\n",
    "\n",
    "        dtype = 'category'  # 원하는 데이터 타입\n",
    "        for column in cat_col:\n",
    "            train[column] = train[column].astype(dtype)\n",
    "            test[column] = test[column].astype(dtype)\n",
    "            \n",
    "    elif types == 'xgboost':\n",
    "        dtype = 'float'  # 원하는 데이터 타입\n",
    "        for column in cat_col:\n",
    "            train[column] = train[column].astype(dtype)\n",
    "            test[column] = test[column].astype(dtype)\n",
    "            \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc05ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_best_threshold(model, X_valid, y_valid):\n",
    "    \n",
    "    # Precision - Recall\n",
    "    y_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_valid, y_pred_proba)\n",
    "    f1_scores = 2*recall*precision / (recall + precision)\n",
    "    cat_best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    y_pred_custom_threshold = (y_pred_proba >= cat_best_threshold).astype(int)\n",
    "    \n",
    "    return thresholds, y_pred_custom_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bee5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_optuna(train, cat_features_indices):\n",
    "    X = train.drop(columns=['target'])\n",
    "    y = train['target']\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "            'seed': 42,\n",
    "        }\n",
    "\n",
    "        model = XGBClassifier(eval_metric='logloss', **params, early_stopping_rounds = 50)\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "\n",
    "        # 검증 세트에 대한 예측 및 평가\n",
    "        preds = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "        # thresholds\n",
    "        precision, recall, thresholds = precision_recall_curve(y_valid, preds)\n",
    "        f1_scores = 2*recall*precision / (recall + precision)\n",
    "        cat_best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        y_pred_custom_threshold_cat = (preds >= cat_best_threshold).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_valid, y_pred_custom_threshold_cat)\n",
    "\n",
    "        return f1\n",
    "\n",
    "    # Optuna 스터디 생성 및 최적화\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    # 최적의 하이퍼파라미터 출력\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "        \n",
    "    \n",
    "#     study_best_trial_params = {\n",
    "#         'n_estimators': 389,\n",
    "#         'max_depth': 7,\n",
    "#         'learning_rate': 0.5624862523377674,\n",
    "#         'subsample': 0.6901977494513396,\n",
    "#         'colsample_bytree': 0.6626522287203345,\n",
    "#         'gamma': 1.5788663422268037,\n",
    "#         'lambda': 0.006161637899604562,\n",
    "#         'alpha': 0.040928088401419954\n",
    "#     }\n",
    "    \n",
    "    return study.best_trial.params, X, y, X_train.index, X_valid.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f131662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_optuna(train, cat_features_indices):\n",
    "\n",
    "    X = train.drop(columns=['target'])\n",
    "    y = train['target']\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    def objective(trial):\n",
    "        lgbm_params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 400, 1500),\n",
    "            \"max_depth\": trial.suggest_int('max_depth', 3, 63),\n",
    "            \"learning_rate\": trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True), \n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "            \"min_child_weight\": trial.suggest_float('min_child_weight', 0.5, 4),\n",
    "            \"min_child_samples\": trial.suggest_int('min_child_samples', 5, 100),\n",
    "            \"subsample\": trial.suggest_float('subsample', 0.4, 1),\n",
    "            \"subsample_freq\": trial.suggest_int('subsample_freq', 0, 5),\n",
    "            \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.2, 1),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 2, 64),\n",
    "        }\n",
    "\n",
    "        model = LGBMClassifier(**lgbm_params, device='cpu', random_state=42, verbose=-1)\n",
    "\n",
    "        # 범주형 피처 적용\n",
    "        model.fit(X_train, y_train, categorical_feature=cat_features_indices,\n",
    "            eval_set = [(X_valid, y_valid)],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 검증 세트에 대한 예측 및 평가\n",
    "        preds = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "        # thresholds\n",
    "        precision, recall, thresholds = precision_recall_curve(y_valid, preds)\n",
    "        f1_scores = 2*recall*precision / (recall + precision)\n",
    "        cat_best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        y_pred_custom_threshold_cat = (preds >= cat_best_threshold).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_valid, y_pred_custom_threshold_cat)\n",
    "\n",
    "        return f1\n",
    "\n",
    "    # Optuna 스터디 생성 및 최적화\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    # 최적의 하이퍼파라미터 출력\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "#     study_best_trial_params = {\n",
    "#         'n_estimators': 1181,\n",
    "#         'max_depth': 42,\n",
    "#         'learning_rate': 0.009444269250537143,\n",
    "#         'reg_alpha': 0.0358194186029774,\n",
    "#         'reg_lambda': 0.001046166296905767,\n",
    "#         'min_child_weight': 3.3802455616568117,\n",
    "#         'min_child_samples': 38,\n",
    "#         'subsample': 0.4032508293056122,\n",
    "#         'subsample_freq': 0,\n",
    "#         'colsample_bytree': 0.2541295048133576,\n",
    "#         'num_leaves': 62\n",
    "#     }\n",
    "        \n",
    "    return study.best_trial.params, X, y, X_train.index, X_valid.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c3b707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_optuna(train, cat_features_indices):\n",
    "    \n",
    "    # train X, y\n",
    "    X = train.drop(columns=['target'])\n",
    "    y = train['target']\n",
    "\n",
    "    # $plit \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Pooling\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_features_indices)\n",
    "    valid_pool = Pool(X_valid, y_valid, cat_features=cat_features_indices)\n",
    "    \n",
    "    # tuning parameters\n",
    "    def objective(trial):\n",
    "        # 하이퍼파라미터를 샘플링\n",
    "        params = {\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1.0, log=True),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-2, 10.0),\n",
    "            \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 1e-9, 10.0),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "            \"od_type\": trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
    "            \"od_wait\": trial.suggest_int(\"od_wait\", 10, 50),\n",
    "            \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "#             \"scale_pos_weight\": trial.suggest_int('scale_pos_weight', 6, 10),\n",
    "            \"verbose\": 0,\n",
    "            \"random_seed\": 42,\n",
    "            'one_hot_max_size': 4\n",
    "        }\n",
    "\n",
    "        # CatBoost 모델 학습\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=0)\n",
    "\n",
    "        # 검증 세트에 대한 예측 및 평가\n",
    "        preds = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "        # thresholds\n",
    "        precision, recall, thresholds = precision_recall_curve(y_valid, preds)\n",
    "        f1_scores = 2*recall*precision / (recall + precision)\n",
    "        cat_best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        y_pred_custom_threshold_cat = (preds >= cat_best_threshold).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_valid, y_pred_custom_threshold_cat)\n",
    "        \n",
    "        return f1\n",
    "\n",
    "    # Optuna 스터디 생성 및 최적화\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    # 최적의 하이퍼파라미터 출력\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "#     study_best_trial_params = {\n",
    "#         'iterations': 800,\n",
    "#         'depth': 7,\n",
    "#         'learning_rate': 0.810235620776663,\n",
    "#         'l2_leaf_reg': 9.445546463334189,\n",
    "#         'border_count': 175,\n",
    "#         'random_strength': 9.076647952917511,\n",
    "#         'bagging_temperature': 0.940243954743633,\n",
    "#         'od_type': 'IncToDec',\n",
    "#         'od_wait': 23,\n",
    "#         'boosting_type': 'Plain'\n",
    "#     }\n",
    "    \n",
    "    return study.best_trial.params, X, y, X_train.index, X_valid.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a443902e",
   "metadata": {},
   "source": [
    "## 3. Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae0c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준\n",
    "columnname = ['Equipment', 'Receip No Collect Result', 'Production Qty Collect Result', 'PalletID Collect Result', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4faaed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop oolumns\n",
    "drop_col = [\n",
    "    \n",
    "    # 단일 칼럼\n",
    "    'Wip Line_Dam',\n",
    "    'Process Desc._Dam',\n",
    "    'Insp. Seq No._Dam',\n",
    "    'Insp Judge Code_Dam',\n",
    "    'Wip Line_Fill1',\n",
    "    'Process Desc._Fill1',\n",
    "    'Insp. Seq No._Fill1',\n",
    "    'Insp Judge Code_Fill1',\n",
    "    'Wip Line_Fill2',\n",
    "    'Process Desc._Fill2',\n",
    "    'Insp. Seq No._Fill2',\n",
    "    'Insp Judge Code_Fill2',\n",
    "    'Wip Line_AutoClave',\n",
    "    'Process Desc._AutoClave',\n",
    "    'Equipment_AutoClave',\n",
    "    'Insp. Seq No._AutoClave',\n",
    "    'Insp Judge Code_AutoClave',\n",
    "    'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave',\n",
    "    'GMES_ORIGIN_INSP_JUDGE_CODE Unit Time_AutoClave',\n",
    "    'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave',\n",
    "    \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2',\n",
    "    'HEAD Standby Position X Collect Result_Fill2',\n",
    "    'HEAD Standby Position Y Collect Result_Fill2',\n",
    "    'HEAD Standby Position Z Collect Result_Fill2',\n",
    "    'Head Clean Position X Collect Result_Fill2',\n",
    "    'Head Clean Position Y Collect Result_Fill2',\n",
    "    'Head Clean Position Z Collect Result_Fill2',\n",
    "    'Head Purge Position X Collect Result_Fill2',\n",
    "    'Head Purge Position Y Collect Result_Fill2',\n",
    "    'Head Purge Position Z Collect Result_Fill2',\n",
    "    \n",
    "    'DISCHARGED SPEED OF RESIN Collect Result_Fill2',\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill2',\n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill2',\n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill2',\n",
    "    'Dispense Volume(Stage1) Collect Result_Fill2',\n",
    "    'Dispense Volume(Stage2) Collect Result_Fill2',\n",
    "    'Dispense Volume(Stage3) Collect Result_Fill2',\n",
    "    \n",
    "    'HEAD Standby Position X Collect Result_Dam',\n",
    "    'HEAD Standby Position Y Collect Result_Dam',\n",
    "    'HEAD Standby Position Z Collect Result_Dam',\n",
    "    'Head Clean Position X Collect Result_Dam',\n",
    "    'Head Clean Position Y Collect Result_Dam',\n",
    "    'Head Purge Position X Collect Result_Dam',\n",
    "    'Head Purge Position Y Collect Result_Dam',\n",
    "    'Head Zero Position X Collect Result_Dam',\n",
    "    'Head Zero Position Y Collect Result_Dam',\n",
    "    'Head Zero Position Z Collect Result_Dam',\n",
    "    \n",
    "    '1st Pressure Judge Value_AutoClave',\n",
    "    '2nd Pressure Judge Value_AutoClave',\n",
    "    '3rd Pressure Judge Value_AutoClave',\n",
    "    'Chamber Temp. Judge Value_AutoClave',\n",
    "    \n",
    "    'HEAD Standby Position X Collect Result_Fill1',\n",
    "    'HEAD Standby Position Y Collect Result_Fill1',\n",
    "    'HEAD Standby Position Z Collect Result_Fill1',\n",
    "    'Head Clean Position X Collect Result_Fill1',\n",
    "    'Head Clean Position Y Collect Result_Fill1',\n",
    "    'Head Clean Position Z Collect Result_Fill1',\n",
    "    'Head Purge Position X Collect Result_Fill1',\n",
    "    'Head Purge Position Y Collect Result_Fill1',\n",
    "\n",
    "    # Cure 변수는 거의 동일함 -> equipment별로 dam은 동일하기 때문에 자르기\n",
    "    'CURE END POSITION X Collect Result_Fill2',\n",
    "    'CURE END POSITION Z Collect Result_Fill2',\n",
    "    'CURE END POSITION Θ Collect Result_Fill2',\n",
    "    'CURE STANDBY POSITION X Collect Result_Fill2',\n",
    "    'CURE STANDBY POSITION Z Collect Result_Fill2',\n",
    "    'CURE STANDBY POSITION Θ Collect Result_Fill2',\n",
    "    'CURE START POSITION X Collect Result_Fill2',\n",
    "    'CURE START POSITION Z Collect Result_Fill2',\n",
    "    'CURE START POSITION Θ Collect Result_Fill2',\n",
    "\n",
    "    'CURE END POSITION X Collect Result_Dam',\n",
    "    'CURE END POSITION Z Collect Result_Dam',\n",
    "    'CURE END POSITION Θ Collect Result_Dam',\n",
    "    'CURE STANDBY POSITION X Collect Result_Dam',\n",
    "    'CURE STANDBY POSITION Z Collect Result_Dam',\n",
    "    'CURE STANDBY POSITION Θ Collect Result_Dam',\n",
    "    'CURE START POSITION X Collect Result_Dam',\n",
    "    'CURE START POSITION Z Collect Result_Dam',\n",
    "    'CURE START POSITION Θ Collect Result_Dam',\n",
    "    \n",
    "    # 라인 서클 축약해서 넣어둠\n",
    "    'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Circle4 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Circle4 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Circle4 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line4 Distance Speed Collect Result_Dam',\n",
    "    \n",
    "    # 중복 변수\n",
    "    'PalletID Collect Result_Fill1',\n",
    "    'Production Qty Collect Result_Fill1',\n",
    "    'Receip No Collect Result_Fill1',\n",
    "    'PalletID Collect Result_Fill2',\n",
    "    'Production Qty Collect Result_Fill2',\n",
    "    'Receip No Collect Result_Fill2',\n",
    "    'Equipment_Fill1',\n",
    "    'Model.Suffix_Fill1',\n",
    "    'Workorder_Fill1',\n",
    "    'Equipment_Fill2',\n",
    "    'Model.Suffix_Fill2',\n",
    "    'Workorder_Fill2',\n",
    "    'Model.Suffix_AutoClave',\n",
    "    'Workorder_AutoClave',\n",
    "    'Workorder_Dam',\n",
    "    ####################################################################\n",
    "    # 새로운 변수(파생변수 생성 도중 제거하고 싶은 변수 넣기)\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2794d",
   "metadata": {},
   "source": [
    "## 4. Matched Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a483379",
   "metadata": {},
   "source": [
    "### 뒤로 밀린 데이터 원상복구 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12dda308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280/691509256.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.     0.012  0.    ...  0.    -0.019  0.   ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dam.loc[dam['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].isin(['OK', np.nan]), dam.columns[24:]] = dam_mask\n",
      "/tmp/ipykernel_280/691509256.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[114.612 114.612  85.    ...  85.    114.612  85.   ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  fill2.loc[fill2['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].isin(['OK', np.nan]), fill2.columns[24:]] = fill2_mask\n",
      "/tmp/ipykernel_280/691509256.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.054  0.     0.    ...  0.     0.     0.   ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dam.loc[dam['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].isin(['OK', np.nan]), dam.columns[24:]] = dam_mask\n",
      "/tmp/ipykernel_280/691509256.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[85. 85. 85. ... 85. 85. 85.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  fill2.loc[fill2['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].isin(['OK', np.nan]), fill2.columns[24:]] = fill2_mask\n"
     ]
    }
   ],
   "source": [
    "# 위치 옮기기\n",
    "train_move = move_data(train)\n",
    "test_move = move_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12049aa2",
   "metadata": {},
   "source": [
    "### Modified Equipment data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0314fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equipment 번호만 가져오기\n",
    "train_move['Equipment_Dam'] = train_move['Equipment_Dam'].str.slice(15, 16)\n",
    "train_move['Equipment_Fill1'] = train_move['Equipment_Fill1'].str.slice(17, 18)\n",
    "train_move['Equipment_Fill2'] = train_move['Equipment_Fill2'].str.slice(17, 18)\n",
    "\n",
    "test_move['Equipment_Dam'] = test_move['Equipment_Dam'].str.slice(15, 16)\n",
    "test_move['Equipment_Fill1'] = test_move['Equipment_Fill1'].str.slice(17, 18)\n",
    "test_move['Equipment_Fill2'] = test_move['Equipment_Fill2'].str.slice(17, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c8dbe",
   "metadata": {},
   "source": [
    "### Type Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18ac0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입 변경하기\n",
    "type_change = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
    "    'Equipment_Dam',\n",
    "    'Equipment_Fill1',\n",
    "    'Equipment_Fill2'\n",
    "]\n",
    "\n",
    "types = [\n",
    "    'float64', 'float64', 'float64', 'int64', 'int64', 'int64'\n",
    "]\n",
    "for i, t in zip(type_change, types):\n",
    "    train_move[i] = train_move[i].astype(t)\n",
    "    test_move[i] = test_move[i].astype(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba82c00",
   "metadata": {},
   "source": [
    "### Fill1의 X좌표 바꾸기\n",
    "\n",
    "- 바꿔야할 칼럼  \n",
    "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  \n",
    "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  \n",
    "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  \n",
    "Dispense Volume(Stage1) Collect Result_Fill1  \n",
    "Dispense Volume(Stage2) Collect Result_Fill1  \n",
    "Dispense Volume(Stage3) Collect Result_Fill1  \n",
    "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1  \n",
    "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1  \n",
    "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1  \n",
    "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1  \n",
    "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1  \n",
    "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1  \n",
    "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1  \n",
    "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1  \n",
    "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24790210",
   "metadata": {},
   "source": [
    "### Equipment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c20f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100대 값을 갖는 X위치 1, 3 체인지\n",
    "condition = (train_move['Equipment_Fill1'] == 1) & (train_move['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] < 200)\n",
    "condition2 = (test_move['Equipment_Fill1'] == 1) & (test_move['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] < 200)\n",
    "\n",
    "# 바꿔야 되는 칼럼\n",
    "As = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "Bs = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "# 교환\n",
    "for a, b in zip(As, Bs):\n",
    "    train_move.loc[condition, [a, b]] = train_move.loc[condition, [b, a]].values\n",
    "    test_move.loc[condition2, [a, b]] = test_move.loc[condition2, [b, a]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d8197e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400대 값을 갖는 X위치 1, 2 체인지\n",
    "condition = (train_move['Equipment_Fill1'] == 1) & (train_move['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].between(400, 500))\n",
    "condition2 = (test_move['Equipment_Fill1'] == 1) & (test_move['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].between(400, 500))\n",
    "\n",
    "# 바꿔야 되는 칼럼\n",
    "As = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "Bs = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "# 교환\n",
    "for a, b in zip(As, Bs):\n",
    "    train_move.loc[condition, [a, b]] = train_move.loc[condition, [b, a]].values\n",
    "    test_move.loc[condition2, [a, b]] = test_move.loc[condition2, [b, a]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162a696",
   "metadata": {},
   "source": [
    "### Equipment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69733236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400대 값을 갖는 X위치 1, 2 체인지\n",
    "condition = (train_move['Equipment_Fill1'] == 2) & (train_move['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].between(400, 500))\n",
    "condition2 = (test_move['Equipment_Fill1'] == 2) & (test_move['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].between(400, 500))\n",
    "\n",
    "# 바꿔야 되는 칼럼\n",
    "As = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "Bs = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "# 교환\n",
    "for a, b in zip(As, Bs):\n",
    "    train_move.loc[condition, [a, b]] = train_move.loc[condition, [b, a]].values\n",
    "    test_move.loc[condition2, [a, b]] = test_move.loc[condition2, [b, a]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53b83a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100대 값을 갖는 X위치 1, 3 체인지\n",
    "condition = (train_move['Equipment_Fill1'] == 2) & (train_move['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] > 800)\n",
    "condition2 = (test_move['Equipment_Fill1'] == 2) & (test_move['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] > 800)\n",
    "\n",
    "# 바꿔야 되는 칼럼\n",
    "As = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "Bs = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "# 교환\n",
    "for a, b in zip(As, Bs):\n",
    "    train_move.loc[condition, [a, b]] = train_move.loc[condition, [b, a]].values\n",
    "    test_move.loc[condition2, [a, b]] = test_move.loc[condition2, [b, a]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04c94abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바뀐 데이터 이름 바꾸기\n",
    "df_train = train_move.copy()\n",
    "df_test = test_move.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc05aa",
   "metadata": {},
   "source": [
    "### New Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712525b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불일치 변수\n",
    "df_train['inconsistant'] = 0\n",
    "df_test['inconsistant'] = 0\n",
    "\n",
    "# 장착\n",
    "for i in columnname:\n",
    "    inconsistant(df_train, i, 'inconsistant', True)\n",
    "    inconsistant(df_test, i, 'inconsistant', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3ed4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간이 0이하, 900이상인 값은 이상치로 분류\n",
    "for j in ['Machine Tact time Collect Result_Dam', 'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Fill2']:\n",
    "    cri = [\n",
    "        df_train[j] <= 0,\n",
    "        df_train[j] > 900\n",
    "    ]\n",
    "    cri2 = [\n",
    "        df_test[j] <= 0,\n",
    "        df_test[j] > 900\n",
    "    ]\n",
    "    con = [\n",
    "        1, 1\n",
    "    ]\n",
    "    df_train['inconsistant'] = np.select(cri, con, default = df_train['inconsistant'])\n",
    "    df_test['inconsistant'] = np.select(cri2, con, default = df_test['inconsistant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad0716",
   "metadata": {},
   "source": [
    "### Speed Line & Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b63870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라인별로 속도가 같아야 정상이다.\n",
    "df_train['Stage1 Line Sum Speed_Dam'] = df_train['Stage1 Line1 Distance Speed Collect Result_Dam'] + df_train['Stage1 Line2 Distance Speed Collect Result_Dam'] + df_train['Stage1 Line3 Distance Speed Collect Result_Dam'] + df_train['Stage1 Line4 Distance Speed Collect Result_Dam']\n",
    "df_train['Stage2 Line Sum Speed_Dam'] = df_train['Stage2 Line1 Distance Speed Collect Result_Dam'] + df_train['Stage2 Line2 Distance Speed Collect Result_Dam'] + df_train['Stage2 Line3 Distance Speed Collect Result_Dam'] + df_train['Stage2 Line4 Distance Speed Collect Result_Dam']\n",
    "df_train['Stage3 Line Sum Speed_Dam'] = df_train['Stage3 Line1 Distance Speed Collect Result_Dam'] + df_train['Stage3 Line2 Distance Speed Collect Result_Dam'] + df_train['Stage3 Line3 Distance Speed Collect Result_Dam'] + df_train['Stage3 Line4 Distance Speed Collect Result_Dam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6a1957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라인별로 속도가 같아야 정상이다.\n",
    "df_test['Stage1 Line Sum Speed_Dam'] = df_test['Stage1 Line1 Distance Speed Collect Result_Dam'] + df_test['Stage1 Line2 Distance Speed Collect Result_Dam'] + df_test['Stage1 Line3 Distance Speed Collect Result_Dam'] + df_test['Stage1 Line4 Distance Speed Collect Result_Dam']\n",
    "df_test['Stage2 Line Sum Speed_Dam'] = df_test['Stage2 Line1 Distance Speed Collect Result_Dam'] + df_test['Stage2 Line2 Distance Speed Collect Result_Dam'] + df_test['Stage2 Line3 Distance Speed Collect Result_Dam'] + df_test['Stage2 Line4 Distance Speed Collect Result_Dam']\n",
    "df_test['Stage3 Line Sum Speed_Dam'] = df_test['Stage3 Line1 Distance Speed Collect Result_Dam'] + df_test['Stage3 Line2 Distance Speed Collect Result_Dam'] + df_test['Stage3 Line3 Distance Speed Collect Result_Dam'] + df_test['Stage3 Line4 Distance Speed Collect Result_Dam']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a9884",
   "metadata": {},
   "source": [
    "### time 보정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a2bfef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time 보정하기\n",
    "df_train['round_1st_time'] = round(df_train['1st Pressure 1st Pressure Unit Time_AutoClave'], -1)\n",
    "df_train['round_2nd_time'] = round(df_train['2nd Pressure Unit Time_AutoClave'], -1)\n",
    "df_train['round_3rd_time'] = round(df_train['3rd Pressure Unit Time_AutoClave'], -1)\n",
    "df_train['all_time'] = round(df_train['Chamber Temp. Unit Time_AutoClave'], -1)\n",
    "\n",
    "df_test['round_1st_time'] = round(df_test['1st Pressure 1st Pressure Unit Time_AutoClave'], -1)\n",
    "df_test['round_2nd_time'] = round(df_test['2nd Pressure Unit Time_AutoClave'], -1)\n",
    "df_test['round_3rd_time'] = round(df_test['3rd Pressure Unit Time_AutoClave'], -1)\n",
    "df_test['all_time'] = round(df_test['Chamber Temp. Unit Time_AutoClave'], -1)\n",
    "\n",
    "time_col = [\n",
    "    '1st Pressure 1st Pressure Unit Time_AutoClave',\n",
    "    '2nd Pressure Unit Time_AutoClave',\n",
    "    '3rd Pressure Unit Time_AutoClave',\n",
    "    'Chamber Temp. Unit Time_AutoClave'\n",
    "]\n",
    "\n",
    "# 적용\n",
    "df_train = df_train.drop(columns = time_col, axis = 1)\n",
    "df_test = df_test.drop(columns = time_col, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2822a9",
   "metadata": {},
   "source": [
    "### Fill2 경화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c5a0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cure 위치 차이 즉 방향을 나타내는 변수 생성\n",
    "df_train['cure_x_direction_fill'] = np.where(df_train['CURE START POSITION X Collect Result_Fill2'] - df_train['CURE END POSITION X Collect Result_Fill2'] > 0, 1, -1)\n",
    "df_train['cure_y_dist_fill'] = df_train['CURE START POSITION Z Collect Result_Fill2'] - df_train['CURE END POSITION Z Collect Result_Fill2']\n",
    "\n",
    "df_test['cure_x_direction_fill'] = np.where(df_test['CURE START POSITION X Collect Result_Fill2'] - df_test['CURE END POSITION X Collect Result_Fill2'] > 0, 1, -1)\n",
    "df_test['cure_y_dist_fill'] = df_test['CURE START POSITION Z Collect Result_Fill2'] - df_test['CURE END POSITION Z Collect Result_Fill2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad827a",
   "metadata": {},
   "source": [
    "### 각 좌표별 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fe3f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Minus1_Dam']= df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] - df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam']\n",
    "df_train['Minus2_Dam']= df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam'] - df_train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "df_test['Minus1_Dam']= df_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] - df_test['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam']\n",
    "df_test['Minus2_Dam']= df_test['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam'] - df_test['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "df_train['Minus1_Fill1']= df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] - df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1']\n",
    "df_train['Minus2_Fill1']= df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'] - df_train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "df_test['Minus1_Fill1']= df_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] - df_test['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1']\n",
    "df_test['Minus2_Fill1']= df_test['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'] - df_test['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "df_train['Minus1Y_Dam']= df_train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'] - df_train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam']\n",
    "df_train['Minus2Y_Dam']= df_train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'] - df_train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "df_test['Minus1Y_Dam']= df_test['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'] - df_test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam']\n",
    "df_test['Minus2Y_Dam']= df_test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'] - df_test['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "df_train['Minus1Y_Fill1']= df_train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'] - df_train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1']\n",
    "df_train['Minus2Y_Fill1']= df_train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'] - df_train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "df_test['Minus1Y_Fill1']= df_test['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'] - df_test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1']\n",
    "df_test['Minus2Y_Fill1']= df_test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'] - df_test['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "df_train['Minus1Y_Dam'] = df_train['Minus1Y_Dam'].apply(lambda x: 1 if x > 2 or x < -2 else 0)\n",
    "df_train['Minus2Y_Dam'] = df_train['Minus2Y_Dam'].apply(lambda x: 1 if x > 2 or x < -2 else 0)\n",
    "\n",
    "df_test['Minus1Y_Dam'] = df_test['Minus1Y_Dam'].apply(lambda x: 1 if x > 2 or x < -2 else 0)\n",
    "df_test['Minus2Y_Dam'] = df_test['Minus2Y_Dam'].apply(lambda x: 1 if x > 2 or x < -2 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaeb695",
   "metadata": {},
   "source": [
    "### 타입 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c767600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2'] = df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2'].astype(float)\n",
    "df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'] = df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af017c",
   "metadata": {},
   "source": [
    "### Workorder 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "beb21a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['workorder_first'] = df_train['Workorder_Dam'].str.slice(0, 2)\n",
    "df_train['workorder_third'] = df_train['Workorder_Dam'].str.slice(2, 4)\n",
    "\n",
    "df_test['workorder_first'] = df_test['Workorder_Dam'].str.slice(0, 2)\n",
    "df_test['workorder_third'] = df_test['Workorder_Dam'].str.slice(2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ecde90",
   "metadata": {},
   "source": [
    "### Columns Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7952ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수많은 칼럼 버리기\n",
    "df_train = df_train.drop(columns = drop_col, axis = 1)\n",
    "df_test = df_test.drop(columns = drop_col, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304c102",
   "metadata": {},
   "source": [
    "### Type 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfbf219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "categorical_features = ['workorder_first', 'workorder_third', 'Model.Suffix_Dam']\n",
    "\n",
    "# 시드 설정\n",
    "np.random.seed(42)\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_train[feature] = le.fit_transform(df_train[feature])\n",
    "    \n",
    "    # 검증 데이터에 있는 새로운 값에 대해 처리\n",
    "    unique_values = set(df_test[feature].unique()) - set(le.classes_)\n",
    "    if unique_values:\n",
    "        # 새로운 값들을 인코딩할 무작위 숫자 생성\n",
    "        new_labels = np.random.randint(0, len(le.classes_), size=len(unique_values))\n",
    "        # 새로운 값들을 인코딩\n",
    "        le.classes_ = np.append(le.classes_, list(unique_values))\n",
    "        le.transform(list(unique_values))  # transform을 호출해서 classes_ 업데이트\n",
    "    \n",
    "    df_test[feature] = le.transform(df_test[feature])\n",
    "    label_encoders[feature] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2543ee",
   "metadata": {},
   "source": [
    "### target 0, 1 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07b35369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target'] = np.where(df_train['target'] == 'Normal', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951eea9",
   "metadata": {},
   "source": [
    "### 이름 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07a344fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dic = {\n",
    "    'Equipment_Dam': 'equipment',\n",
    "    'Model.Suffix_Dam': 'model_suffix',\n",
    "    'Workorder_Dam': 'workorder',\n",
    "    'PalletID Collect Result_Dam':'pallet_id',\n",
    "    'Production Qty Collect Result_Dam': 'qty',\n",
    "    'Receip No Collect Result_Dam': 'receip'\n",
    "}\n",
    "\n",
    "df_train.rename(columns = name_dic, inplace = True)\n",
    "df_test.rename(columns = name_dic, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04f43922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect result 빼자\n",
    "df_train.columns = df_train.columns.str.replace(' Collect Result', '')\n",
    "df_test.columns = df_test.columns.str.replace(' Collect Result', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c2f19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM이 공백 넣지 말래요\n",
    "df_train.columns = df_train.columns.str.replace(' ', '_')\n",
    "df_test.columns = df_test.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb2b45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 애초에 비정상인 값은 굳이 학습시킬 이유 없다.\n",
    "df_train_adj = df_train[df_train['inconsistant'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f18698d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 집단으로 나누기\n",
    "equip1 = df_train_adj[df_train_adj['equipment'] == 1]\n",
    "equip2 = df_train_adj[df_train_adj['equipment'] == 2]\n",
    "\n",
    "equip1_test = df_test[df_test['equipment'] == 1]\n",
    "equip2_test = df_test[df_test['equipment'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ce605a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280/4311638.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  equip1.drop(['inconsistant', 'equipment'], axis = 1, inplace = True)\n",
      "/tmp/ipykernel_280/4311638.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  equip2.drop(['inconsistant', 'equipment'], axis = 1, inplace = True)\n",
      "/tmp/ipykernel_280/4311638.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  equip1_test.drop(['inconsistant', 'equipment'], axis = 1, inplace = True)\n",
      "/tmp/ipykernel_280/4311638.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  equip2_test.drop(['inconsistant', 'equipment'], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# 집단을 나누는 기준을 제외시키기\n",
    "equip1.drop(['inconsistant', 'equipment'], axis = 1, inplace = True)\n",
    "equip2.drop(['inconsistant', 'equipment'], axis = 1, inplace = True)\n",
    "\n",
    "equip1_test.drop(['inconsistant', 'equipment'], axis = 1, inplace = True)\n",
    "equip2_test.drop(['inconsistant', 'equipment'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "578286fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_suffix', 'CURE_SPEED_Dam', 'DISCHARGED_SPEED_OF_RESIN_Dam',\n",
       "       'DISCHARGED_TIME_OF_RESIN(Stage1)_Dam',\n",
       "       'DISCHARGED_TIME_OF_RESIN(Stage2)_Dam',\n",
       "       'DISCHARGED_TIME_OF_RESIN(Stage3)_Dam', 'Dispense_Volume(Stage1)_Dam',\n",
       "       'Dispense_Volume(Stage2)_Dam', 'Dispense_Volume(Stage3)_Dam',\n",
       "       'HEAD_NORMAL_COORDINATE_X_AXIS(Stage1)_Dam',\n",
       "       'HEAD_NORMAL_COORDINATE_X_AXIS(Stage2)_Dam',\n",
       "       'HEAD_NORMAL_COORDINATE_X_AXIS(Stage3)_Dam',\n",
       "       'HEAD_NORMAL_COORDINATE_Y_AXIS(Stage1)_Dam',\n",
       "       'HEAD_NORMAL_COORDINATE_Y_AXIS(Stage2)_Dam',\n",
       "       'HEAD_NORMAL_COORDINATE_Y_AXIS(Stage3)_Dam',\n",
       "       'HEAD_NORMAL_COORDINATE_Z_AXIS(Stage1)_Dam',\n",
       "       'HEAD_NORMAL_COORDINATE_Z_AXIS(Stage2)_Dam',\n",
       "       'HEAD_NORMAL_COORDINATE_Z_AXIS(Stage3)_Dam',\n",
       "       'Head_Clean_Position_Z_Dam', 'Head_Purge_Position_Z_Dam',\n",
       "       'Machine_Tact_time_Dam', 'pallet_id', 'qty', 'receip',\n",
       "       'Stage1_Circle1_Distance_Speed_Dam',\n",
       "       'Stage2_Circle1_Distance_Speed_Dam',\n",
       "       'Stage3_Circle1_Distance_Speed_Dam', 'THICKNESS_1_Dam',\n",
       "       'THICKNESS_2_Dam', 'THICKNESS_3_Dam', 'DISCHARGED_SPEED_OF_RESIN_Fill1',\n",
       "       'DISCHARGED_TIME_OF_RESIN(Stage1)_Fill1',\n",
       "       'DISCHARGED_TIME_OF_RESIN(Stage2)_Fill1',\n",
       "       'DISCHARGED_TIME_OF_RESIN(Stage3)_Fill1',\n",
       "       'Dispense_Volume(Stage1)_Fill1', 'Dispense_Volume(Stage2)_Fill1',\n",
       "       'Dispense_Volume(Stage3)_Fill1',\n",
       "       'HEAD_NORMAL_COORDINATE_X_AXIS(Stage1)_Fill1',\n",
       "       'HEAD_NORMAL_COORDINATE_X_AXIS(Stage2)_Fill1',\n",
       "       'HEAD_NORMAL_COORDINATE_X_AXIS(Stage3)_Fill1',\n",
       "       'HEAD_NORMAL_COORDINATE_Y_AXIS(Stage1)_Fill1',\n",
       "       'HEAD_NORMAL_COORDINATE_Y_AXIS(Stage2)_Fill1',\n",
       "       'HEAD_NORMAL_COORDINATE_Y_AXIS(Stage3)_Fill1',\n",
       "       'HEAD_NORMAL_COORDINATE_Z_AXIS(Stage1)_Fill1',\n",
       "       'HEAD_NORMAL_COORDINATE_Z_AXIS(Stage2)_Fill1',\n",
       "       'HEAD_NORMAL_COORDINATE_Z_AXIS(Stage3)_Fill1',\n",
       "       'Head_Purge_Position_Z_Fill1', 'Machine_Tact_time_Fill1',\n",
       "       'CURE_SPEED_Fill2', 'Machine_Tact_time_Fill2', '1st_Pressure_AutoClave',\n",
       "       '2nd_Pressure_AutoClave', '3rd_Pressure_AutoClave',\n",
       "       'Chamber_Temp._AutoClave', 'target', 'Stage1_Line_Sum_Speed_Dam',\n",
       "       'Stage2_Line_Sum_Speed_Dam', 'Stage3_Line_Sum_Speed_Dam',\n",
       "       'round_1st_time', 'round_2nd_time', 'round_3rd_time', 'all_time',\n",
       "       'cure_x_direction_fill', 'cure_y_dist_fill', 'Minus1_Dam', 'Minus2_Dam',\n",
       "       'Minus1_Fill1', 'Minus2_Fill1', 'Minus1Y_Dam', 'Minus2Y_Dam',\n",
       "       'Minus1Y_Fill1', 'Minus2Y_Fill1', 'workorder_first', 'workorder_third',\n",
       "       '1st_Pressure_x_Time', '2nd_Pressure_x_Time', '3rd_Pressure_x_Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equip1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8cf1e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "\n",
      "model_suffix 변수의 검정\n",
      "Chi square: 10.12947141892338\n",
      "P-value: 0.1193\n",
      "===============================\n",
      "\n",
      "CURE_SPEED_Dam 변수의 검정\n",
      "Chi square: 17.763952563218012\n",
      "P-value: 0.0014\n",
      "===============================\n",
      "\n",
      "DISCHARGED_SPEED_OF_RESIN_Dam 변수의 검정\n",
      "Chi square: 67.04620917313018\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "DISCHARGED_TIME_OF_RESIN(Stage1)_Dam 변수의 검정\n",
      "LeveneResult(statistic=34788.391699280284, pvalue=0.0)\n",
      "BartlettResult(statistic=105445.10615572892, pvalue=0.0)\n",
      "TtestResult(statistic=-553.972191169205, pvalue=0.0, df=25151.205176769763)\n",
      "===============================\n",
      "\n",
      "DISCHARGED_TIME_OF_RESIN(Stage2)_Dam 변수의 검정\n",
      "LeveneResult(statistic=79478.53665547512, pvalue=0.0)\n",
      "BartlettResult(statistic=73795.57371022321, pvalue=0.0)\n",
      "TtestResult(statistic=-497.5445477976165, pvalue=0.0, df=25633.968465143844)\n",
      "===============================\n",
      "\n",
      "DISCHARGED_TIME_OF_RESIN(Stage3)_Dam 변수의 검정\n",
      "LeveneResult(statistic=34329.73826270856, pvalue=0.0)\n",
      "BartlettResult(statistic=105226.64413825389, pvalue=0.0)\n",
      "TtestResult(statistic=-556.2591418548592, pvalue=0.0, df=25152.836132511195)\n",
      "===============================\n",
      "\n",
      "Dispense_Volume(Stage1)_Dam 변수의 검정\n",
      "LeveneResult(statistic=12883.138525402992, pvalue=0.0)\n",
      "BartlettResult(statistic=3399.7573576693067, pvalue=0.0)\n",
      "TtestResult(statistic=-368.8410686632538, pvalue=0.0, df=44294.898355916004)\n",
      "===============================\n",
      "\n",
      "Dispense_Volume(Stage2)_Dam 변수의 검정\n",
      "LeveneResult(statistic=4277.70951046081, pvalue=0.0)\n",
      "BartlettResult(statistic=1032.4694610335862, pvalue=1.5728488926703865e-226)\n",
      "TtestResult(statistic=-225.36597996696213, pvalue=0.0, df=47989.8922878818)\n",
      "===============================\n",
      "\n",
      "Dispense_Volume(Stage3)_Dam 변수의 검정\n",
      "LeveneResult(statistic=12848.779842280104, pvalue=0.0)\n",
      "BartlettResult(statistic=3297.8637393754548, pvalue=0.0)\n",
      "TtestResult(statistic=-369.56955657360214, pvalue=0.0, df=44435.575949788894)\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_X_AXIS(Stage1)_Dam 변수의 검정\n",
      "LeveneResult(statistic=32195.024625107704, pvalue=0.0)\n",
      "BartlettResult(statistic=38380.72838542637, pvalue=0.0)\n",
      "TtestResult(statistic=-89488.6694763068, pvalue=0.0, df=27973.65070995524)\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_X_AXIS(Stage2)_Dam 변수의 검정\n",
      "LeveneResult(statistic=24006.50872926884, pvalue=0.0)\n",
      "BartlettResult(statistic=33004.145075940556, pvalue=0.0)\n",
      "TtestResult(statistic=-84667.2433154197, pvalue=0.0, df=28807.273235931396)\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_X_AXIS(Stage3)_Dam 변수의 검정\n",
      "LeveneResult(statistic=25235.199773390865, pvalue=0.0)\n",
      "BartlettResult(statistic=33872.802407900985, pvalue=0.0)\n",
      "TtestResult(statistic=-28833.732093731625, pvalue=0.0, df=28656.55103430536)\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Y_AXIS(Stage1)_Dam 변수의 검정\n",
      "Chi square: 209.98025181969945\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Y_AXIS(Stage2)_Dam 변수의 검정\n",
      "Chi square: 211.15867201127756\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Y_AXIS(Stage3)_Dam 변수의 검정\n",
      "Chi square: 210.0102006973125\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Z_AXIS(Stage1)_Dam 변수의 검정\n",
      "LeveneResult(statistic=18388.285402626894, pvalue=0.0)\n",
      "BartlettResult(statistic=102091.31122270977, pvalue=0.0)\n",
      "TtestResult(statistic=-12447.179433795569, pvalue=0.0, df=25177.9124959555)\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Z_AXIS(Stage2)_Dam 변수의 검정\n",
      "LeveneResult(statistic=18388.285402626894, pvalue=0.0)\n",
      "BartlettResult(statistic=102091.31122270977, pvalue=0.0)\n",
      "TtestResult(statistic=-12447.179433795569, pvalue=0.0, df=25177.9124959555)\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Z_AXIS(Stage3)_Dam 변수의 검정\n",
      "LeveneResult(statistic=18388.285402626894, pvalue=0.0)\n",
      "BartlettResult(statistic=102091.31122270977, pvalue=0.0)\n",
      "TtestResult(statistic=-12447.179433795569, pvalue=0.0, df=25177.9124959555)\n",
      "===============================\n",
      "\n",
      "Head_Clean_Position_Z_Dam 변수의 검정\n",
      "Chi square: 206.8916907375713\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Head_Purge_Position_Z_Dam 변수의 검정\n",
      "Chi square: 208.1457329502154\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Machine_Tact_time_Dam 변수의 검정\n",
      "LeveneResult(statistic=68102.84168237253, pvalue=0.0)\n",
      "BartlettResult(statistic=177377.74062369153, pvalue=0.0)\n",
      "TtestResult(statistic=-705.9628611109748, pvalue=0.0, df=24977.256831346538)\n",
      "===============================\n",
      "\n",
      "pallet_id 변수의 검정\n",
      "Chi square: 11.465434961650942\n",
      "P-value: 0.1196\n",
      "===============================\n",
      "\n",
      "qty 변수의 검정\n",
      "LeveneResult(statistic=50094.90332139869, pvalue=0.0)\n",
      "BartlettResult(statistic=275776.8320490404, pvalue=0.0)\n",
      "TtestResult(statistic=-236.48514629730917, pvalue=0.0, df=24967.19914865523)\n",
      "===============================\n",
      "\n",
      "receip 변수의 검정\n",
      "Chi square: 14.966517030505225\n",
      "P-value: 0.0006\n",
      "===============================\n",
      "\n",
      "Stage1_Circle1_Distance_Speed_Dam 변수의 검정\n",
      "Chi square: 204.39791725791713\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Stage2_Circle1_Distance_Speed_Dam 변수의 검정\n",
      "Chi square: 172.71247074760504\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Stage3_Circle1_Distance_Speed_Dam 변수의 검정\n",
      "Chi square: 204.43064061189565\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "THICKNESS_1_Dam 변수의 검정\n",
      "Chi square: 21.526856006577127\n",
      "P-value: 0.0015\n",
      "===============================\n",
      "\n",
      "THICKNESS_2_Dam 변수의 검정\n",
      "Chi square: 21.681738673755962\n",
      "P-value: 0.0029\n",
      "===============================\n",
      "\n",
      "THICKNESS_3_Dam 변수의 검정\n",
      "Chi square: 21.526856006577127\n",
      "P-value: 0.0015\n",
      "===============================\n",
      "\n",
      "DISCHARGED_SPEED_OF_RESIN_Fill1 변수의 검정\n",
      "Chi square: 93.8240990352927\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "DISCHARGED_TIME_OF_RESIN(Stage1)_Fill1 변수의 검정\n",
      "Chi square: 85.54313780178936\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "DISCHARGED_TIME_OF_RESIN(Stage2)_Fill1 변수의 검정\n",
      "LeveneResult(statistic=6750.98883157651, pvalue=0.0)\n",
      "BartlettResult(statistic=17362.09751393946, pvalue=0.0)\n",
      "TtestResult(statistic=-1018.9135667643588, pvalue=0.0, df=33264.207706814275)\n",
      "===============================\n",
      "\n",
      "DISCHARGED_TIME_OF_RESIN(Stage3)_Fill1 변수의 검정\n",
      "LeveneResult(statistic=3916.3402040657725, pvalue=0.0)\n",
      "BartlettResult(statistic=11449.029008502732, pvalue=0.0)\n",
      "TtestResult(statistic=-4027.552715593382, pvalue=0.0, df=36506.357631503)\n",
      "===============================\n",
      "\n",
      "Dispense_Volume(Stage1)_Fill1 변수의 검정\n",
      "Chi square: 85.54313780178937\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Dispense_Volume(Stage2)_Fill1 변수의 검정\n",
      "LeveneResult(statistic=6259.885324650095, pvalue=0.0)\n",
      "BartlettResult(statistic=15253.373434290863, pvalue=0.0)\n",
      "TtestResult(statistic=-1016.1376318630474, pvalue=0.0, df=34267.86286099541)\n",
      "===============================\n",
      "\n",
      "Dispense_Volume(Stage3)_Fill1 변수의 검정\n",
      "LeveneResult(statistic=4569.269814643541, pvalue=0.0)\n",
      "BartlettResult(statistic=2870.6385356830633, pvalue=0.0)\n",
      "TtestResult(statistic=-4981.546139769436, pvalue=0.0, df=45041.758559592956)\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_X_AXIS(Stage1)_Fill1 변수의 검정\n",
      "Chi square: 61.647878810316996\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_X_AXIS(Stage2)_Fill1 변수의 검정\n",
      "Chi square: 251.61015178056172\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_X_AXIS(Stage3)_Fill1 변수의 검정\n",
      "Chi square: 128.99976840881232\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Y_AXIS(Stage1)_Fill1 변수의 검정\n",
      "Chi square: 198.22797083940372\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Y_AXIS(Stage2)_Fill1 변수의 검정\n",
      "Chi square: 6.871878029293587\n",
      "P-value: 0.2303\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Y_AXIS(Stage3)_Fill1 변수의 검정\n",
      "Chi square: 196.4265618550391\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Z_AXIS(Stage1)_Fill1 변수의 검정\n",
      "Chi square: 109.11825245330104\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Z_AXIS(Stage2)_Fill1 변수의 검정\n",
      "Chi square: 109.11825245330104\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "HEAD_NORMAL_COORDINATE_Z_AXIS(Stage3)_Fill1 변수의 검정\n",
      "Chi square: 109.11825245330104\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Head_Purge_Position_Z_Fill1 변수의 검정\n",
      "Chi square: 181.5526077475593\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Machine_Tact_time_Fill1 변수의 검정\n",
      "LeveneResult(statistic=25361.106817277105, pvalue=0.0)\n",
      "BartlettResult(statistic=179956.26146030528, pvalue=0.0)\n",
      "TtestResult(statistic=-644.6020148172692, pvalue=0.0, df=24976.25000801877)\n",
      "===============================\n",
      "\n",
      "CURE_SPEED_Fill2 변수의 검정\n",
      "Chi square: 12.629742821770703\n",
      "P-value: 0.0817\n",
      "===============================\n",
      "\n",
      "Machine_Tact_time_Fill2 변수의 검정\n",
      "LeveneResult(statistic=1348.988879147188, pvalue=1.9959209197026926e-291)\n",
      "BartlettResult(statistic=68412.83842091718, pvalue=0.0)\n",
      "TtestResult(statistic=-1710.903600155717, pvalue=0.0, df=25799.796503412697)\n",
      "===============================\n",
      "\n",
      "1st_Pressure_AutoClave 변수의 검정\n",
      "LeveneResult(statistic=1270.0387941920576, pvalue=1.0437009028112685e-274)\n",
      "BartlettResult(statistic=153244.17810967867, pvalue=0.0)\n",
      "TtestResult(statistic=-170.51303803605728, pvalue=0.0, df=24993.984192478176)\n",
      "===============================\n",
      "\n",
      "2nd_Pressure_AutoClave 변수의 검정\n",
      "LeveneResult(statistic=284.1661117512932, pvalue=1.3928280512295372e-63)\n",
      "BartlettResult(statistic=17570.821317825692, pvalue=0.0)\n",
      "TtestResult(statistic=-210.52113837248947, pvalue=0.0, df=33172.42876035455)\n",
      "===============================\n",
      "\n",
      "3rd_Pressure_AutoClave 변수의 검정\n",
      "LeveneResult(statistic=1178.1349687777108, pvalue=3.2630520958380813e-255)\n",
      "BartlettResult(statistic=76213.60964874132, pvalue=0.0)\n",
      "TtestResult(statistic=-300.20105266484194, pvalue=0.0, df=25570.91209056149)\n",
      "===============================\n",
      "\n",
      "Chamber_Temp._AutoClave 변수의 검정\n",
      "LeveneResult(statistic=67094.1534661223, pvalue=0.0)\n",
      "BartlettResult(statistic=90654.55042789337, pvalue=0.0)\n",
      "TtestResult(statistic=-2872.040598363416, pvalue=0.0, df=25302.106411817582)\n",
      "===============================\n",
      "\n",
      "target 변수의 검정\n",
      "Chi square: 24967.999999999996\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Stage1_Line_Sum_Speed_Dam 변수의 검정\n",
      "Chi square: 215.46267596174852\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Stage2_Line_Sum_Speed_Dam 변수의 검정\n",
      "Chi square: 185.0546186139892\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Stage3_Line_Sum_Speed_Dam 변수의 검정\n",
      "Chi square: 207.30356737550056\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "round_1st_time 변수의 검정\n",
      "Chi square: 286.7066042592236\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "round_2nd_time 변수의 검정\n",
      "Chi square: 109.74185474981766\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "round_3rd_time 변수의 검정\n",
      "Chi square: 150.48352576489143\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "all_time 변수의 검정\n",
      "Chi square: 415.54576765950725\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "cure_x_direction_fill 변수의 검정\n",
      "Chi square: 2.8184632054891487\n",
      "P-value: 0.0932\n",
      "===============================\n",
      "\n",
      "cure_y_dist_fill 변수의 검정\n",
      "Chi square: 54.70894516138322\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Minus1_Dam 변수의 검정\n",
      "Chi square: 239.21131969577357\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Minus2_Dam 변수의 검정\n",
      "Chi square: 171.9968525957022\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Minus1_Fill1 변수의 검정\n",
      "LeveneResult(statistic=8370.48553407143, pvalue=0.0)\n",
      "BartlettResult(statistic=31736.351302986914, pvalue=0.0)\n",
      "TtestResult(statistic=-71240.88872066447, pvalue=0.0, df=29039.95157506244)\n",
      "===============================\n",
      "\n",
      "Minus2_Fill1 변수의 검정\n",
      "Chi square: 240.45090035434748\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Minus1Y_Dam 변수의 검정\n",
      "Chi square: 0.0\n",
      "P-value: 1.0000\n",
      "===============================\n",
      "\n",
      "Minus2Y_Dam 변수의 검정\n",
      "Chi square: 0.0\n",
      "P-value: 1.0000\n",
      "===============================\n",
      "\n",
      "Minus1Y_Fill1 변수의 검정\n",
      "Chi square: 206.2487487554876\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "Minus2Y_Fill1 변수의 검정\n",
      "Chi square: 206.9205281228942\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "workorder_first 변수의 검정\n",
      "Chi square: 234.32408168972236\n",
      "P-value: 0.0000\n",
      "===============================\n",
      "\n",
      "workorder_third 변수의 검정\n",
      "Chi square: 8.562601325451933\n",
      "P-value: 0.0138\n",
      "===============================\n",
      "\n",
      "1st_Pressure_x_Time 변수의 검정\n",
      "LeveneResult(statistic=7612.875224634705, pvalue=0.0)\n",
      "BartlettResult(statistic=140509.4687895565, pvalue=0.0)\n",
      "TtestResult(statistic=-1554.63153742464, pvalue=0.0, df=25011.972110489518)\n",
      "===============================\n",
      "\n",
      "2nd_Pressure_x_Time 변수의 검정\n",
      "LeveneResult(statistic=83139.74248741427, pvalue=0.0)\n",
      "BartlettResult(statistic=189208.82704484806, pvalue=0.0)\n",
      "TtestResult(statistic=-170.48450236820824, pvalue=0.0, df=24973.38473806952)\n",
      "===============================\n",
      "\n",
      "3rd_Pressure_x_Time 변수의 검정\n",
      "LeveneResult(statistic=3193.7615855861104, pvalue=0.0)\n",
      "BartlettResult(statistic=127774.58740185667, pvalue=0.0)\n",
      "TtestResult(statistic=-1609.7385153067742, pvalue=0.0, df=25041.987438327524)\n"
     ]
    }
   ],
   "source": [
    "# univariate validation을 통한 변수 제외 목록 뽑기\n",
    "except_value = []\n",
    "for i in equip1.columns:\n",
    "    print(\"===============================\\n\")\n",
    "    print(f\"{i} 변수의 검정\")\n",
    "    \n",
    "    if len(np.unique(equip1[i])) < 14:\n",
    "        chiresult = chi2_contingency(pd.crosstab(equip1[i], equip1['target']), correction=False)\n",
    "        print('Chi square: {}'.format(chiresult[0]))\n",
    "        print('P-value: {:.4f}'.format(chiresult[1]))\n",
    "        \n",
    "        if chiresult[1] > 0.05:\n",
    "            except_value.append(i)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        l = levene(equip1['target'], equip1[i])\n",
    "        b = bartlett(equip1['target'], equip1[i])\n",
    "        print(l)\n",
    "        print(b)\n",
    "        \n",
    "        \n",
    "        if (l[1] >= 0.05) or (b[1] >= 0.05):\n",
    "            t = ttest_ind(equip1['target'], equip1[i], equal_var = True)\n",
    "            print(t)\n",
    "            \n",
    "        else:\n",
    "            t = ttest_ind(equip1['target'], equip1[i], equal_var = False)\n",
    "            print(t)\n",
    "            \n",
    "        if t[1] > 0.05:\n",
    "            except_value.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f7dc9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_suffix',\n",
       " 'pallet_id',\n",
       " 'HEAD_NORMAL_COORDINATE_Y_AXIS(Stage2)_Fill1',\n",
       " 'CURE_SPEED_Fill2',\n",
       " 'cure_x_direction_fill',\n",
       " 'Minus1Y_Dam',\n",
       " 'Minus2Y_Dam']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "except_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32232f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    make_scorer,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier, plot_metric\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(f1_score, pos_label=1, average = 'binary')\n",
    "\n",
    "def get_clf_eval(y_test, y_pred=None):\n",
    "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
    "\n",
    "    print(\"오차행렬:\\n\", confusion)\n",
    "    print(\"\\n정확도: {:.4f}\".format(accuracy))\n",
    "    print(\"정밀도: {:.4f}\".format(precision))\n",
    "    print(\"재현율: {:.4f}\".format(recall))\n",
    "    print(\"F1: {:.4f}\".format(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea357c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e2487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# divide\n",
    "dam = train.filter(regex='_Dam')\n",
    "fill1 = train.filter(regex='_Fill1')\n",
    "fill2 = train.filter(regex='_Fill2')\n",
    "autoclave = train.filter(regex='_AutoClave')\n",
    "target = train['target']\n",
    "\n",
    "# dam\n",
    "dam = dam.dropna(axis=1, how='all')\n",
    "dam = dam.drop(columns='HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam')\n",
    "dam_mask = dam[dam['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].isin(['OK', np.nan])].iloc[:, 24:].shift(-1, axis = 1).values\n",
    "dam.loc[dam['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].isin(['OK', np.nan]), dam.columns[24:]] = dam_mask\n",
    "dam = dam.drop(columns='WorkMode Collect Result_Dam')\n",
    "\n",
    "# fill1\n",
    "fill1 = fill1.dropna(axis=1, how='all')\n",
    "fill1 = fill1.drop(columns='HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1')\n",
    "fill1_mask = fill1[fill1['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].isin(['OK', np.nan])].iloc[:, 14:].shift(-1, axis = 1).values\n",
    "fill1.loc[fill1['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].isin(['OK', np.nan]), fill1.columns[14:]] = fill1_mask\n",
    "fill1 = fill1.drop(columns='WorkMode Collect Result_Fill1')\n",
    "\n",
    "# fill2\n",
    "fill2 = fill2.dropna(axis=1, how='all')\n",
    "fill2 = fill2.drop(columns='HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2')\n",
    "fill2_mask = fill2[fill2['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].isin(['OK', np.nan])].iloc[:, 24:].shift(-1, axis = 1).values\n",
    "fill2.loc[fill2['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].isin(['OK', np.nan]), fill2.columns[24:]] = fill2_mask\n",
    "fill2 = fill2.drop(columns='WorkMode Collect Result_Fill2')\n",
    "\n",
    "# CONCAT\n",
    "train = pd.concat([dam, fill1, fill2, autoclave, target], axis=1)\n",
    "\n",
    "# divide\n",
    "dam_test = test.filter(regex='_Dam')\n",
    "fill1_test = test.filter(regex='_Fill1')\n",
    "fill2_test = test.filter(regex='_Fill2')\n",
    "autoclave_test = test.filter(regex='_AutoClave')\n",
    "\n",
    "# dam\n",
    "dam_test = dam_test.dropna(axis=1, how='all')\n",
    "dam_test = dam_test.drop(columns='HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam')\n",
    "dam_mask_test = dam_test[dam_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].isin(['OK', np.nan])].iloc[:, 24:].shift(-1, axis = 1).values\n",
    "dam_test.loc[dam_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].isin(['OK', np.nan]), dam_test.columns[24:]] = dam_mask_test\n",
    "dam_test = dam_test.drop(columns='WorkMode Collect Result_Dam')\n",
    "\n",
    "# fill1\n",
    "fill1_test = fill1_test.dropna(axis=1, how='all')\n",
    "fill1_test = fill1_test.drop(columns='HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1')\n",
    "fill1_mask_test = fill1_test[fill1_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].isin(['OK', np.nan])].iloc[:, 14:].shift(-1, axis = 1).values\n",
    "fill1_test.loc[fill1_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].isin(['OK', np.nan]), fill1_test.columns[14:]] = fill1_mask_test\n",
    "fill1_test = fill1_test.drop(columns='WorkMode Collect Result_Fill1')\n",
    "\n",
    "# fill2\n",
    "fill2_test = fill2_test.dropna(axis=1, how='all')\n",
    "fill2_test = fill2_test.drop(columns='HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2')\n",
    "fill2_mask_test = fill2_test[fill2_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].isin(['OK', np.nan])].iloc[:, 24:].shift(-1, axis = 1).values\n",
    "fill2_test.loc[fill2_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].isin(['OK', np.nan]), fill2_test.columns[24:]] = fill2_mask_test\n",
    "fill2_test = fill2_test.drop(columns='WorkMode Collect Result_Fill2')\n",
    "\n",
    "# CONCAT\n",
    "test = pd.concat([dam_test, fill1_test, fill2_test, autoclave_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0a0d3",
   "metadata": {},
   "source": [
    "# Swap 전 좌표 평균보정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8521597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] = train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float)\n",
    "train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'] = train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float)\n",
    "\n",
    "\n",
    "# 이동 전\n",
    "X_sum_down_1 = train[train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float) < 500]['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float).mean()\n",
    "X_sum_down_2 = train[train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float) < 500]['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float).mean()\n",
    "X_sum_up_1 = train[train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float) > 500]['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float).mean()\n",
    "X_sum_up_2 = train[train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float) > 500]['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float).mean()\n",
    "\n",
    "X_sum_down = (X_sum_down_1 - X_sum_down_2) / 2 # stage1에서 빼고, Stage3에서 더하기 <500\n",
    "X_sum_up = (X_sum_up_2 - X_sum_up_1) / 2 # stage1에서 더하고, Stage 3에서 빼기\n",
    "\n",
    "train.loc[train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] += X_sum_up\n",
    "train.loc[train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'] -= X_sum_up\n",
    "\n",
    "train.loc[train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float) < 500, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] -= X_sum_down\n",
    "train.loc[train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float) < 500, 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'] += X_sum_down\n",
    "\n",
    "# test\n",
    "test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] = test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float)\n",
    "test['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'] = test['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float)\n",
    "\n",
    "\n",
    "# 이동 전\n",
    "test.loc[test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] += X_sum_up\n",
    "test.loc[test['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'] -= X_sum_up\n",
    "\n",
    "test.loc[test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].astype(float) < 500, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] -= X_sum_down\n",
    "test.loc[test['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float) < 500, 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'] += X_sum_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d9f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "Y_sum_dam_1 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'].astype(float) < 500]['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'].astype(float).mean()\n",
    "Y_sum_dam_2 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'].astype(float) > 500]['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'].astype(float).mean()\n",
    "\n",
    "train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'] = Y_sum_dam_1 + Y_sum_dam_2 - train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam']\n",
    "\n",
    "Y_sum_dam_3 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'].astype(float) < 500]['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'].astype(float).mean()\n",
    "Y_sum_dam_4 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'].astype(float) > 500]['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'].astype(float).mean()\n",
    "\n",
    "train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'] = Y_sum_dam_3 + Y_sum_dam_4 - train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "Y_sum_dam_5 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'].astype(float) < 500]['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'].astype(float).mean()\n",
    "Y_sum_dam_6 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'].astype(float) > 500]['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'].astype(float).mean()\n",
    "\n",
    "train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'] = Y_sum_dam_5 + Y_sum_dam_6 - train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam']\n",
    "\n",
    "Y_sum_fill_1 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'].astype(float) > 500]['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'].astype(float).mean()\n",
    "Y_sum_fill_2 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'].astype(float) < 500]['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'].astype(float).mean()\n",
    "\n",
    "train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'] = Y_sum_fill_1 + Y_sum_fill_2 - train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1']\n",
    "\n",
    "Y_sum_fill_3 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'].astype(float) > 500]['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'].astype(float).mean()\n",
    "Y_sum_fill_4 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'].astype(float) < 500]['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'].astype(float).mean()\n",
    "\n",
    "train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'] = Y_sum_fill_3 + Y_sum_fill_4 - train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "Y_sum_fill_5 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'].astype(float) > 500]['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'].astype(float).mean()\n",
    "Y_sum_fill_6 = train[train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'].astype(float) < 500]['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'].astype(float).mean()\n",
    "train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'] = Y_sum_fill_5 + Y_sum_fill_6 - train.loc[train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1']\n",
    "\n",
    "\n",
    "# test\n",
    "test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'] = Y_sum_dam_1 + Y_sum_dam_2 - test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam']\n",
    "test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'] = Y_sum_dam_5 + Y_sum_dam_6 - test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam']\n",
    "test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'] = Y_sum_dam_3 + Y_sum_dam_4 - test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam']\n",
    "test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'] = Y_sum_fill_1 + Y_sum_fill_2 - test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1']\n",
    "test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'] = Y_sum_fill_5 + Y_sum_fill_6 - test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1']\n",
    "test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'] = Y_sum_fill_3 + Y_sum_fill_4 - test.loc[test['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'].astype(float) > 500, 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3924fa6",
   "metadata": {},
   "source": [
    "# Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3eb8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_columns(df, condition, col1, col2):\n",
    "    # 조건에 해당하는 행 필터링\n",
    "    filtered_df = df[condition]\n",
    "    \n",
    "    # 값 교환\n",
    "    df.loc[condition, [col1, col2]] = filtered_df[[col1, col2]].copy().iloc[:, ::-1].values\n",
    "\n",
    "    return df\n",
    "\n",
    "### Train\n",
    "# 조건을 만족하는 행 인덱스를 찾음\n",
    "condition = train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float) >= 200\n",
    "\n",
    "# DISCHARGED TIME OF RESIN(Stage1) \n",
    "swap_columns(train, condition, 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam')\n",
    "\n",
    "# Dispense Volume(Stage1)\n",
    "swap_columns(train, condition, 'Dispense Volume(Stage1) Collect Result_Dam', 'Dispense Volume(Stage3) Collect Result_Dam')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Y AXIS(Stage1)\n",
    "swap_columns(train, condition, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam', 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Z AXIS(Stage1)\n",
    "swap_columns(train, condition, 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam', 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam')\n",
    "\n",
    "# Stage1 Circle1 Distance Speed Collect\n",
    "swap_columns(train, condition, 'Stage1 Circle1 Distance Speed Collect Result_Dam', 'Stage3 Circle1 Distance Speed Collect Result_Dam')\n",
    "swap_columns(train, condition, 'Stage1 Circle2 Distance Speed Collect Result_Dam', 'Stage3 Circle2 Distance Speed Collect Result_Dam')\n",
    "swap_columns(train, condition, 'Stage1 Circle3 Distance Speed Collect Result_Dam', 'Stage3 Circle3 Distance Speed Collect Result_Dam')\n",
    "swap_columns(train, condition, 'Stage1 Circle4 Distance Speed Collect Result_Dam', 'Stage3 Circle4 Distance Speed Collect Result_Dam')\n",
    "\n",
    "# Stage1 Line1 Distance Speed Collect\n",
    "swap_columns(train, condition, 'Stage1 Line1 Distance Speed Collect Result_Dam', 'Stage3 Line1 Distance Speed Collect Result_Dam')\n",
    "swap_columns(train, condition, 'Stage1 Line2 Distance Speed Collect Result_Dam', 'Stage3 Line2 Distance Speed Collect Result_Dam')\n",
    "swap_columns(train, condition, 'Stage1 Line3 Distance Speed Collect Result_Dam', 'Stage3 Line3 Distance Speed Collect Result_Dam')\n",
    "swap_columns(train, condition, 'Stage1 Line4 Distance Speed Collect Result_Dam', 'Stage3 Line4 Distance Speed Collect Result_Dam')\n",
    "\n",
    "# THICKNESS 1\n",
    "# swap_columns(train, condition, 'THICKNESS 1 Collect Result_Dam', 'THICKNESS 3 Collect Result_Dam')\n",
    "\n",
    "### 젤 마지막에 와야됨!!!!\n",
    "# HEAD NORMAL COORDINATE X AXIS(Stage1)\n",
    "swap_columns(train, condition, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam', 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam')\n",
    "\n",
    "\n",
    "### Test\n",
    "# 조건을 만족하는 행 인덱스를 찾음\n",
    "condition = test['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'].astype(float) >= 200\n",
    "\n",
    "# DISCHARGED TIME OF RESIN(Stage1) \n",
    "swap_columns(test, condition, 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam')\n",
    "\n",
    "# Dispense Volume(Stage1)\n",
    "swap_columns(test, condition, 'Dispense Volume(Stage1) Collect Result_Dam', 'Dispense Volume(Stage3) Collect Result_Dam')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Y AXIS(Stage1)\n",
    "swap_columns(test, condition, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam', 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Z AXIS(Stage1)\n",
    "swap_columns(test, condition, 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam', 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam')\n",
    "\n",
    "# Stage1 Circle1 Distance Speed Collect\n",
    "swap_columns(test, condition, 'Stage1 Circle1 Distance Speed Collect Result_Dam', 'Stage3 Circle1 Distance Speed Collect Result_Dam')\n",
    "swap_columns(test, condition, 'Stage1 Circle2 Distance Speed Collect Result_Dam', 'Stage3 Circle2 Distance Speed Collect Result_Dam')\n",
    "swap_columns(test, condition, 'Stage1 Circle3 Distance Speed Collect Result_Dam', 'Stage3 Circle3 Distance Speed Collect Result_Dam')\n",
    "swap_columns(test, condition, 'Stage1 Circle4 Distance Speed Collect Result_Dam', 'Stage3 Circle4 Distance Speed Collect Result_Dam')\n",
    "\n",
    "# Stage1 Line1 Distance Speed Collect\n",
    "swap_columns(test, condition, 'Stage1 Line1 Distance Speed Collect Result_Dam', 'Stage3 Line1 Distance Speed Collect Result_Dam')\n",
    "swap_columns(test, condition, 'Stage1 Line2 Distance Speed Collect Result_Dam', 'Stage3 Line2 Distance Speed Collect Result_Dam')\n",
    "swap_columns(test, condition, 'Stage1 Line3 Distance Speed Collect Result_Dam', 'Stage3 Line3 Distance Speed Collect Result_Dam')\n",
    "swap_columns(test, condition, 'Stage1 Line4 Distance Speed Collect Result_Dam', 'Stage3 Line4 Distance Speed Collect Result_Dam')\n",
    "\n",
    "# THICKNESS 1\n",
    "# swap_columns(train, condition, 'THICKNESS 1 Collect Result_Dam', 'THICKNESS 3 Collect Result_Dam')\n",
    "\n",
    "### 젤 마지막에 와야됨!!!!\n",
    "# HEAD NORMAL COORDINATE X AXIS(Stage1)\n",
    "swap_columns(test, condition, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam', 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d60d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train\n",
    "condition = train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'].astype(float) > 500\n",
    "\n",
    "# DISCHARGED TIME OF RESIN(Stage1)\n",
    "swap_columns(train, condition, 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1')\n",
    "\n",
    "# Dispense Volume(Stage1)\n",
    "swap_columns(train, condition, 'Dispense Volume(Stage1) Collect Result_Fill1', 'Dispense Volume(Stage2) Collect Result_Fill1')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Y AXIS(Stage1)\n",
    "swap_columns(train, condition, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Z AXIS(Stage1)\n",
    "swap_columns(train, condition, 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1')\n",
    "\n",
    "# 반드시 마지막으로 와야함!!!!\n",
    "# HEAD NORMAL COORDINATE X AXIS(Stage1)\n",
    "swap_columns(train, condition, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1')\n",
    "\n",
    "### Test\n",
    "condition = test['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'].astype(float) > 500\n",
    "\n",
    "# DISCHARGED TIME OF RESIN(Stage1)\n",
    "swap_columns(test, condition, 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1')\n",
    "\n",
    "# Dispense Volume(Stage1)\n",
    "swap_columns(test, condition, 'Dispense Volume(Stage1) Collect Result_Fill1', 'Dispense Volume(Stage2) Collect Result_Fill1')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Y AXIS(Stage1)\n",
    "swap_columns(test, condition, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Z AXIS(Stage1)\n",
    "swap_columns(test, condition, 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1')\n",
    "\n",
    "# 반드시 마지막으로 와야함!!!!\n",
    "# HEAD NORMAL COORDINATE X AXIS(Stage1)\n",
    "swap_columns(test, condition, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f94ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train\n",
    "# 조건을 만족하는 행 인덱스를 찾음\n",
    "condition = train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].astype(float) < 200\n",
    "\n",
    "# DISCHARGED TIME OF RESIN(Stage1)\n",
    "swap_columns(train, condition, 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1')\n",
    "\n",
    "# Dispense Volume(Stage1)\n",
    "swap_columns(train, condition, 'Dispense Volume(Stage1) Collect Result_Fill1', 'Dispense Volume(Stage3) Collect Result_Fill1')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Y AXIS(Stage1)\n",
    "swap_columns(train, condition, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Z AXIS(Stage1)\n",
    "swap_columns(train, condition, 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1')\n",
    "\n",
    "# 반드시 마지막으로 와야함!!!!\n",
    "# HEAD NORMAL COORDINATE X AXIS(Stage1)\n",
    "swap_columns(train, condition, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1')\n",
    "\n",
    "### Test\n",
    "condition = test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].astype(float) < 200\n",
    "\n",
    "# DISCHARGED TIME OF RESIN(Stage1)\n",
    "swap_columns(test, condition, 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1')\n",
    "\n",
    "# Dispense Volume(Stage1)\n",
    "swap_columns(test, condition, 'Dispense Volume(Stage1) Collect Result_Fill1', 'Dispense Volume(Stage3) Collect Result_Fill1')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Y AXIS(Stage1)\n",
    "swap_columns(test, condition, 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1')\n",
    "\n",
    "# HEAD NORMAL COORDINATE Z AXIS(Stage1)\n",
    "swap_columns(test, condition, 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1')\n",
    "\n",
    "# 반드시 마지막으로 와야함!!!!\n",
    "# HEAD NORMAL COORDINATE X AXIS(Stage1)\n",
    "swap_columns(test, condition, 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb062f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train\n",
    "df_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c8dbe",
   "metadata": {},
   "source": [
    "# Type Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_change = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam', 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam', 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1']\n",
    "\n",
    "for i in type_change:\n",
    "    df_train[i] = df_train[i].astype(float)\n",
    "    df_test[i] = df_test[i].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc05aa",
   "metadata": {},
   "source": [
    "# New Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0314fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train\n",
    "test = df_test\n",
    "train['Equipment_Dam'] = train['Equipment_Dam'].str.slice(15, 16)\n",
    "train['Equipment_Fill1'] = train['Equipment_Fill1'].str.slice(17, 18)\n",
    "train['Equipment_Fill2'] = train['Equipment_Fill2'].str.slice(17, 18)\n",
    "\n",
    "test['Equipment_Dam'] = test['Equipment_Dam'].str.slice(15, 16)\n",
    "test['Equipment_Fill1'] = test['Equipment_Fill1'].str.slice(17, 18)\n",
    "test['Equipment_Fill2'] = test['Equipment_Fill2'].str.slice(17, 18)\n",
    "df_train = train\n",
    "df_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712525b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dam, Fill1, Fill2에서 지정된 값이 다를 경우 Abnormal \n",
    "def inconsistant(data, columnname, iwantthiscolumnsname, is_train = True):\n",
    "    # 장비 번호가 다르면 불일치\n",
    "    if is_train:\n",
    "        cri = [\n",
    "            df_train[columnname + '_Dam'] != df_train[columnname + '_Fill1'],\n",
    "            df_train[columnname + '_Dam'] != df_train[columnname + '_Fill2'],\n",
    "            df_train[columnname + '_Fill1'] != df_train[columnname + '_Fill2'],\n",
    "            data[iwantthiscolumnsname] == 1\n",
    "        ]\n",
    "        \n",
    "    else:\n",
    "        cri = [\n",
    "            df_test[columnname + '_Dam'] != df_test[columnname + '_Fill1'],\n",
    "            df_test[columnname + '_Dam'] != df_test[columnname + '_Fill2'],\n",
    "            df_test[columnname + '_Fill1'] != df_test[columnname + '_Fill1'],\n",
    "            data[iwantthiscolumnsname] == 1\n",
    "        ]\n",
    "    con = [1, 1, 1, 1]\n",
    "\n",
    "    data[iwantthiscolumnsname] = np.select(cri, con, default = 0)\n",
    "    \n",
    "# 불일치 변수\n",
    "df_train['inconsistant'] = 0\n",
    "df_test['inconsistant'] = 0\n",
    "\n",
    "# 기준\n",
    "columnname = ['Equipment', 'Receip No Collect Result', 'Production Qty Collect Result', 'PalletID Collect Result', ]\n",
    "\n",
    "# 장착\n",
    "for i in columnname:\n",
    "    inconsistant(df_train, i, 'inconsistant', True)\n",
    "    inconsistant(df_test, i, 'inconsistant', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간이 0이하, 900이상인 값은 이상치로 분류\n",
    "for j in ['Machine Tact time Collect Result_Dam', 'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Fill2']:\n",
    "    cri = [\n",
    "        df_train[j] <= 0,\n",
    "        df_train[j] > 900\n",
    "    ]\n",
    "    cri2 = [\n",
    "        df_test[j] <= 0,\n",
    "        df_test[j] > 900\n",
    "    ]\n",
    "    con = [\n",
    "        1, 1\n",
    "    ]\n",
    "    df_train['inconsistant'] = np.select(cri, con, default = df_train['inconsistant'])\n",
    "    df_test['inconsistant'] = np.select(cri2, con, default = df_test['inconsistant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1103566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['1st Pressure x Time x Temp AutoClave'] = df_train['1st Pressure Collect Result_AutoClave']*df_train['1st Pressure 1st Pressure Unit Time_AutoClave']*df_train['Chamber Temp. Collect Result_AutoClave']\n",
    "df_train['2nd Pressure x Time x Temp AutoClave'] = df_train['2nd Pressure Collect Result_AutoClave']*df_train['2nd Pressure Unit Time_AutoClave']*df_train['Chamber Temp. Collect Result_AutoClave']\n",
    "df_train['3rd Pressure x Time x Temp AutoClave'] = df_train['3rd Pressure Collect Result_AutoClave']*df_train['3rd Pressure Unit Time_AutoClave']*df_train['Chamber Temp. Collect Result_AutoClave']\n",
    "\n",
    "df_test['1st Pressure x Time x Temp AutoClave'] = df_test['1st Pressure Collect Result_AutoClave']*df_test['1st Pressure 1st Pressure Unit Time_AutoClave']*df_test['Chamber Temp. Collect Result_AutoClave']\n",
    "df_test['2nd Pressure x Time x Temp AutoClave'] = df_test['2nd Pressure Collect Result_AutoClave']*df_test['2nd Pressure Unit Time_AutoClave']*df_test['Chamber Temp. Collect Result_AutoClave']\n",
    "df_test['3rd Pressure x Time x Temp AutoClave'] = df_test['3rd Pressure Collect Result_AutoClave']*df_test['3rd Pressure Unit Time_AutoClave']*df_test['Chamber Temp. Collect Result_AutoClave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe3f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Minus1_Dam']= df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] - df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam']\n",
    "df_train['Minus2_Dam']= df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam'] - df_train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "df_test['Minus1_Dam']= df_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] - df_test['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam']\n",
    "df_test['Minus2_Dam']= df_test['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam'] - df_test['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "df_train['Minus1_Fill1']= df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] - df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1']\n",
    "df_train['Minus2_Fill1']= df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'] - df_train['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "df_test['Minus1_Fill1']= df_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] - df_test['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1']\n",
    "df_test['Minus2_Fill1']= df_test['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'] - df_test['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "df_train['Minus1Y_Dam']= df_train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'] - df_train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam']\n",
    "df_train['Minus2Y_Dam']= df_train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'] - df_train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "df_test['Minus1Y_Dam']= df_test['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'] - df_test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam']\n",
    "df_test['Minus2Y_Dam']= df_test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'] - df_test['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "df_train['Minus1Y_Fill1']= df_train['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'] - df_train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1']\n",
    "df_train['Minus2Y_Fill1']= df_train['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'] - df_train['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "df_test['Minus1Y_Fill1']= df_test['HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'] - df_test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1']\n",
    "df_test['Minus2Y_Fill1']= df_test['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'] - df_test['HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "df_train['Minus1Y_Dam'] = df_train['Minus1Y_Dam'].apply(lambda x: 1 if x > 2 or x < -2 else 0)\n",
    "df_train['Minus2Y_Dam'] = df_train['Minus2Y_Dam'].apply(lambda x: 1 if x > 2 or x < -2 else 0)\n",
    "\n",
    "df_test['Minus1Y_Dam'] = df_test['Minus1Y_Dam'].apply(lambda x: 1 if x > 2 or x < -2 else 0)\n",
    "df_test['Minus2Y_Dam'] = df_test['Minus2Y_Dam'].apply(lambda x: 1 if x > 2 or x < -2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c767600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2'] = df_train['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2'].astype(float)\n",
    "df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'] = df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad0716",
   "metadata": {},
   "source": [
    "# Column Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns= [ \n",
    " 'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
    " 'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
    " 'Stage1 Circle4 Distance Speed Collect Result_Dam', \n",
    " 'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
    " 'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
    " 'Stage2 Circle4 Distance Speed Collect Result_Dam', \n",
    " 'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
    " 'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
    " 'Stage3 Circle4 Distance Speed Collect Result_Dam'] )\n",
    "\n",
    "df_test = df_test.rename(columns={'Stage1 Circle1 Distance Speed Collect Result_Dam': 'Stage1 Circle Distance Speed_Dam', \n",
    "                                    'Stage2 Circle1 Distance Speed Collect Result_Dam': 'Stage2 Circle Distance Speed_Dam',\n",
    "                                    'Stage3 Circle1 Distance Speed Collect Result_Dam': 'Stage3 Circle Distance Speed_Dam'})\n",
    "\n",
    "# Dam, Fill2의 경우 Z값이 서로 같다. -> 그렇다면 Fill1은 높이값에서 흔들린 경우가 있다는 것을 의미한다.\n",
    "df_test = df_test.drop(columns= [\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2'\n",
    "])\n",
    "\n",
    "df_test = df_test.rename(columns={'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2': 'HEAD NORMAL COORDINATE Z AXIS_Fill2', \n",
    "                                    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam': 'HEAD NORMAL COORDINATE Z AXIS_Dam',\n",
    "                                    })\n",
    "\n",
    "# Model.Suffix, Workorder이 같다.\n",
    "df_test = df_test.drop(columns=['Model.Suffix_Fill1', 'Model.Suffix_Fill2', 'Model.Suffix_AutoClave'])\n",
    "df_test = df_test.drop(columns=['Workorder_Fill1', 'Workorder_Fill2', 'Workorder_AutoClave'])\n",
    "df_test = df_test.rename(columns={'Workorder_Dam': 'Workorder', 'Model.Suffix_Dam': 'Model.Suffix'})\n",
    "\n",
    "# 의미를 찾을 수 없는 컬럼들 제거\n",
    "df_test = df_test.drop(columns=['Wip Line_Fill1', \n",
    "                                  'Process Desc._Fill1', \n",
    "                                  'Insp. Seq No._Fill1', \n",
    "                                  'Insp Judge Code_Fill1', \n",
    "                                  'Equipment_AutoClave',\n",
    "                                  'Process Desc._AutoClave', \n",
    "                                  'Wip Line_AutoClave', \n",
    "                                  'Insp Judge Code_AutoClave',\n",
    "                                  'Insp. Seq No._AutoClave',\n",
    "                                  '1st Pressure Judge Value_AutoClave', \n",
    "                                  '2nd Pressure Judge Value_AutoClave', \n",
    "                                  '3rd Pressure Judge Value_AutoClave', \n",
    "                                  'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave',\n",
    "                                  'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave',\n",
    "                                  'GMES_ORIGIN_INSP_JUDGE_CODE Unit Time_AutoClave',\n",
    "                                  'Wip Line_Fill2', \n",
    "                                  'Process Desc._Fill2', \n",
    "                                  'Insp. Seq No._Fill2', \n",
    "                                  'Insp Judge Code_Fill2', \n",
    "                                  'Wip Line_Dam', \n",
    "                                  'Process Desc._Dam', \n",
    "                                  'Insp. Seq No._Dam', \n",
    "                                  'Insp Judge Code_Dam',\n",
    "                                  'CURE END POSITION X Collect Result_Dam',\n",
    "                                  'CURE END POSITION Z Collect Result_Dam',\n",
    "                                  'CURE END POSITION Θ Collect Result_Dam',\n",
    "                                  'CURE STANDBY POSITION X Collect Result_Dam',\n",
    "                                  'CURE STANDBY POSITION Z Collect Result_Dam',\n",
    "                                  'CURE STANDBY POSITION Θ Collect Result_Dam',\n",
    "                                  ])  \n",
    "\n",
    "# Fill2는 레진을 살포하지 않는다. UV만 진행하는 과정이므로 싹 삭제해 준다.          \n",
    "df_test = df_test.drop(columns=['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE Z AXIS_Fill2',\n",
    "                                'HEAD Standby Position X Collect Result_Fill2',\n",
    "                                'HEAD Standby Position Y Collect Result_Fill2',\n",
    "                                'HEAD Standby Position Z Collect Result_Fill2',\n",
    "                                'Head Clean Position X Collect Result_Fill2',\n",
    "                                'Head Clean Position Y Collect Result_Fill2',\n",
    "                                'Head Clean Position Z Collect Result_Fill2',\n",
    "                                'Head Purge Position X Collect Result_Fill2',\n",
    "                                'Head Purge Position Y Collect Result_Fill2',\n",
    "                                'Head Purge Position Z Collect Result_Fill2',\n",
    "                                'DISCHARGED SPEED OF RESIN Collect Result_Fill2',\n",
    "                                'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill2',\n",
    "                                'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill2',\n",
    "                                'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill2',\n",
    "                                'Dispense Volume(Stage1) Collect Result_Fill2',\n",
    "                                'Dispense Volume(Stage2) Collect Result_Fill2',\n",
    "                                'Dispense Volume(Stage3) Collect Result_Fill2',])  \n",
    "\n",
    "# 라인별로 속도가 같아야 정상이다.\n",
    "df_test['Stage1 Line diffent Distance Speed_Dam'] = ((df_test['Stage1 Line1 Distance Speed Collect Result_Dam'] != df_test['Stage1 Line2 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_test['Stage1 Line1 Distance Speed Collect Result_Dam'] != df_test['Stage1 Line3 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_test['Stage1 Line1 Distance Speed Collect Result_Dam'] != df_test['Stage1 Line4 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_test['Stage1 Line3 Distance Speed Collect Result_Dam'] != df_test['Stage1 Line4 Distance Speed Collect Result_Dam'])).astype(int)\n",
    "df_test['Stage1 Line Sum Speed_Dam'] = df_test['Stage1 Line1 Distance Speed Collect Result_Dam'] + df_test['Stage1 Line2 Distance Speed Collect Result_Dam'] + df_test['Stage1 Line3 Distance Speed Collect Result_Dam'] + df_test['Stage1 Line4 Distance Speed Collect Result_Dam']\n",
    "\n",
    "df_test['Stage2 Line diffent Distance Speed_Dam'] = ((df_test['Stage2 Line1 Distance Speed Collect Result_Dam'] != df_test['Stage2 Line2 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_test['Stage2 Line1 Distance Speed Collect Result_Dam'] != df_test['Stage2 Line3 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_test['Stage2 Line1 Distance Speed Collect Result_Dam'] != df_test['Stage2 Line4 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_test['Stage2 Line3 Distance Speed Collect Result_Dam'] != df_test['Stage2 Line4 Distance Speed Collect Result_Dam'])).astype(int)\n",
    "df_test['Stage2 Line Sum Speed_Dam'] = df_test['Stage2 Line1 Distance Speed Collect Result_Dam'] + df_test['Stage2 Line2 Distance Speed Collect Result_Dam'] + df_test['Stage2 Line3 Distance Speed Collect Result_Dam'] + df_test['Stage2 Line4 Distance Speed Collect Result_Dam']\n",
    "\n",
    "df_test['Stage3 Line diffent Distance Speed_Dam'] = ((df_test['Stage3 Line1 Distance Speed Collect Result_Dam'] != df_test['Stage3 Line2 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_test['Stage3 Line1 Distance Speed Collect Result_Dam'] != df_test['Stage3 Line3 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_test['Stage3 Line1 Distance Speed Collect Result_Dam'] != df_test['Stage3 Line4 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_test['Stage3 Line3 Distance Speed Collect Result_Dam'] != df_test['Stage3 Line4 Distance Speed Collect Result_Dam'])).astype(int)\n",
    "df_test['Stage3 Line Sum Speed_Dam'] = df_test['Stage3 Line1 Distance Speed Collect Result_Dam'] + df_test['Stage3 Line2 Distance Speed Collect Result_Dam'] + df_test['Stage3 Line3 Distance Speed Collect Result_Dam'] + df_test['Stage3 Line4 Distance Speed Collect Result_Dam']\n",
    "\n",
    "df_test = df_test.drop(columns=[\n",
    "                                'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
    "                                'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
    "                                'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
    "                                'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
    "                                'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
    "                                'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
    "                                'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
    "                                'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
    "                                'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
    "                                'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
    "                                'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
    "                                'Stage3 Line4 Distance Speed Collect Result_Dam',\n",
    "                                ])\n",
    "\n",
    "# 단일값이 하나인 컬럼들, 의미를 찾고싶다면 주석처리 해야하는 것들\n",
    "df_test = df_test.drop(columns=['CURE START POSITION X Collect Result_Dam', # Equipment에 따라서 정해지며, 하나로 책정됨.\n",
    "                                'CURE START POSITION Z Collect Result_Dam', # START POSITION\n",
    "                                'CURE START POSITION Θ Collect Result_Dam', # Equipment에 따라서 정해지며, 하나로 책정됨.\n",
    "                                'HEAD Standby Position X Collect Result_Dam',\n",
    "                                'HEAD Standby Position Y Collect Result_Dam',\n",
    "                                'HEAD Standby Position Z Collect Result_Dam',\n",
    "                                'Head Clean Position X Collect Result_Dam',\n",
    "                                'Head Clean Position Y Collect Result_Dam', # 흔들림에 따라 Z\n",
    "                                'Head Purge Position X Collect Result_Dam',\n",
    "                                'Head Purge Position Y Collect Result_Dam',\n",
    "                                'Head Zero Position X Collect Result_Dam',\n",
    "                                'HEAD Standby Position X Collect Result_Fill1',\n",
    "                                'HEAD Standby Position Y Collect Result_Fill1',\n",
    "                                'HEAD Standby Position Z Collect Result_Fill1',\n",
    "                                'Head Clean Position X Collect Result_Fill1',\n",
    "                                'Head Clean Position Y Collect Result_Fill1',\n",
    "                                'Head Clean Position Z Collect Result_Fill1',\n",
    "                                'Head Purge Position X Collect Result_Fill1',\n",
    "                                'Head Purge Position Y Collect Result_Fill1',\n",
    "                                'CURE END POSITION X Collect Result_Fill2',\n",
    "                                'CURE END POSITION Θ Collect Result_Fill2',\n",
    "                                'CURE STANDBY POSITION X Collect Result_Fill2',\n",
    "                                'CURE STANDBY POSITION Z Collect Result_Fill2',\n",
    "                                'CURE STANDBY POSITION Θ Collect Result_Fill2',\n",
    "                                'CURE START POSITION X Collect Result_Fill2',\n",
    "                                'CURE START POSITION Θ Collect Result_Fill2',\n",
    "                                ])\n",
    "\n",
    "# AutoClave 의미없어보이는거 제거\n",
    "df_test = df_test.drop(columns=[ 'Chamber Temp. Collect Result_AutoClave',\n",
    "                                  'Chamber Temp. Judge Value_AutoClave',\n",
    "                                  'Chamber Temp. Unit Time_AutoClave',\n",
    "                                  '1st Pressure Collect Result_AutoClave',\n",
    "                                  '1st Pressure 1st Pressure Unit Time_AutoClave',\n",
    "                                  '2nd Pressure Collect Result_AutoClave',\n",
    "                                  '2nd Pressure Unit Time_AutoClave',\n",
    "                                  '3rd Pressure Collect Result_AutoClave',\n",
    "                                  '3rd Pressure Unit Time_AutoClave',\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0fd414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 값들이 같은 컬럼 하나로 합치는 과정\n",
    "# 같은 Stage에 Circle 값들끼리 같다.\n",
    "df_train = df_train.drop(columns= [ \n",
    " 'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
    " 'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
    " 'Stage1 Circle4 Distance Speed Collect Result_Dam', \n",
    " 'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
    " 'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
    " 'Stage2 Circle4 Distance Speed Collect Result_Dam', \n",
    " 'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
    " 'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
    " 'Stage3 Circle4 Distance Speed Collect Result_Dam'] )\n",
    "\n",
    "df_train = df_train.rename(columns={'Stage1 Circle1 Distance Speed Collect Result_Dam': 'Stage1 Circle Distance Speed_Dam', \n",
    "                                    'Stage2 Circle1 Distance Speed Collect Result_Dam': 'Stage2 Circle Distance Speed_Dam',\n",
    "                                    'Stage3 Circle1 Distance Speed Collect Result_Dam': 'Stage3 Circle Distance Speed_Dam'})\n",
    "\n",
    "# Dam, Fill2의 경우 Z값이 서로 같다. -> 그렇다면 Fill1은 높이값에서 흔들린 경우가 있다는 것을 의미한다.\n",
    "df_train = df_train.drop(columns= [\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2'\n",
    "])\n",
    "\n",
    "df_train = df_train.rename(columns={'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2': 'HEAD NORMAL COORDINATE Z AXIS_Fill2', \n",
    "                                    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam': 'HEAD NORMAL COORDINATE Z AXIS_Dam',\n",
    "                                    })\n",
    "\n",
    "# Model.Suffix, Workorder이 같다.\n",
    "df_train = df_train.drop(columns=['Model.Suffix_Fill1', 'Model.Suffix_Fill2', 'Model.Suffix_AutoClave'])\n",
    "df_train = df_train.drop(columns=['Workorder_Fill1', 'Workorder_Fill2', 'Workorder_AutoClave'])\n",
    "df_train = df_train.rename(columns={'Workorder_Dam': 'Workorder', 'Model.Suffix_Dam': 'Model.Suffix'})\n",
    "\n",
    "\n",
    "# 의미를 찾을 수 없는 컬럼들 제거\n",
    "df_train = df_train.drop(columns=['Wip Line_Fill1', \n",
    "                                  'Process Desc._Fill1', \n",
    "                                  'Insp. Seq No._Fill1', \n",
    "                                  'Insp Judge Code_Fill1', \n",
    "                                  'Equipment_AutoClave',\n",
    "                                  'Process Desc._AutoClave', \n",
    "                                  'Wip Line_AutoClave', \n",
    "                                  'Insp Judge Code_AutoClave',\n",
    "                                  'Insp. Seq No._AutoClave',\n",
    "                                  '1st Pressure Judge Value_AutoClave', \n",
    "                                  '2nd Pressure Judge Value_AutoClave', \n",
    "                                  '3rd Pressure Judge Value_AutoClave', \n",
    "                                  'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave',\n",
    "                                  'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave',\n",
    "                                  'GMES_ORIGIN_INSP_JUDGE_CODE Unit Time_AutoClave',\n",
    "                                  'Wip Line_Fill2', \n",
    "                                  'Process Desc._Fill2', \n",
    "                                  'Insp. Seq No._Fill2', \n",
    "                                  'Insp Judge Code_Fill2', \n",
    "                                  'Wip Line_Dam', \n",
    "                                  'Process Desc._Dam', \n",
    "                                  'Insp. Seq No._Dam', \n",
    "                                  'Insp Judge Code_Dam',\n",
    "                                  'CURE END POSITION X Collect Result_Dam',\n",
    "                                  'CURE END POSITION Z Collect Result_Dam',\n",
    "                                  'CURE END POSITION Θ Collect Result_Dam',\n",
    "                                  'CURE STANDBY POSITION X Collect Result_Dam',\n",
    "                                  'CURE STANDBY POSITION Z Collect Result_Dam',\n",
    "                                  'CURE STANDBY POSITION Θ Collect Result_Dam',\n",
    "                                  ])  \n",
    "\n",
    "# Fill2는 레진을 살포하지 않는다. UV만 진행하는 과정이므로 싹 삭제해 준다.          \n",
    "df_train = df_train.drop(columns=['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
    "                                'HEAD NORMAL COORDINATE Z AXIS_Fill2',\n",
    "                                'HEAD Standby Position X Collect Result_Fill2',\n",
    "                                'HEAD Standby Position Y Collect Result_Fill2',\n",
    "                                'HEAD Standby Position Z Collect Result_Fill2',\n",
    "                                'Head Clean Position X Collect Result_Fill2',\n",
    "                                'Head Clean Position Y Collect Result_Fill2',\n",
    "                                'Head Clean Position Z Collect Result_Fill2',\n",
    "                                'Head Purge Position X Collect Result_Fill2',\n",
    "                                'Head Purge Position Y Collect Result_Fill2',\n",
    "                                'Head Purge Position Z Collect Result_Fill2',\n",
    "                                'DISCHARGED SPEED OF RESIN Collect Result_Fill2',\n",
    "                                'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill2',\n",
    "                                'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill2',\n",
    "                                'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill2',\n",
    "                                'Dispense Volume(Stage1) Collect Result_Fill2',\n",
    "                                'Dispense Volume(Stage2) Collect Result_Fill2',\n",
    "                                'Dispense Volume(Stage3) Collect Result_Fill2',])  \n",
    "\n",
    "# 라인별로 속도가 같아야 정상이다.\n",
    "df_train['Stage1 Line diffent Distance Speed_Dam'] = ((df_train['Stage1 Line1 Distance Speed Collect Result_Dam'] != df_train['Stage1 Line2 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_train['Stage1 Line1 Distance Speed Collect Result_Dam'] != df_train['Stage1 Line3 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_train['Stage1 Line1 Distance Speed Collect Result_Dam'] != df_train['Stage1 Line4 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_train['Stage1 Line3 Distance Speed Collect Result_Dam'] != df_train['Stage1 Line4 Distance Speed Collect Result_Dam'])).astype(int)\n",
    "df_train['Stage1 Line Sum Speed_Dam'] = df_train['Stage1 Line1 Distance Speed Collect Result_Dam'] + df_train['Stage1 Line2 Distance Speed Collect Result_Dam'] + df_train['Stage1 Line3 Distance Speed Collect Result_Dam'] + df_train['Stage1 Line4 Distance Speed Collect Result_Dam']\n",
    "\n",
    "df_train['Stage2 Line diffent Distance Speed_Dam'] = ((df_train['Stage2 Line1 Distance Speed Collect Result_Dam'] != df_train['Stage2 Line2 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_train['Stage2 Line1 Distance Speed Collect Result_Dam'] != df_train['Stage2 Line3 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_train['Stage2 Line1 Distance Speed Collect Result_Dam'] != df_train['Stage2 Line4 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_train['Stage2 Line3 Distance Speed Collect Result_Dam'] != df_train['Stage2 Line4 Distance Speed Collect Result_Dam'])).astype(int)\n",
    "df_train['Stage2 Line Sum Speed_Dam'] = df_train['Stage2 Line1 Distance Speed Collect Result_Dam'] + df_train['Stage2 Line2 Distance Speed Collect Result_Dam'] + df_train['Stage2 Line3 Distance Speed Collect Result_Dam'] + df_train['Stage2 Line4 Distance Speed Collect Result_Dam']\n",
    "\n",
    "df_train['Stage3 Line diffent Distance Speed_Dam'] = ((df_train['Stage3 Line1 Distance Speed Collect Result_Dam'] != df_train['Stage3 Line2 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_train['Stage3 Line1 Distance Speed Collect Result_Dam'] != df_train['Stage3 Line3 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_train['Stage3 Line1 Distance Speed Collect Result_Dam'] != df_train['Stage3 Line4 Distance Speed Collect Result_Dam']) |\n",
    "                                                  (df_train['Stage3 Line3 Distance Speed Collect Result_Dam'] != df_train['Stage3 Line4 Distance Speed Collect Result_Dam'])).astype(int)\n",
    "df_train['Stage3 Line Sum Speed_Dam'] = df_train['Stage3 Line1 Distance Speed Collect Result_Dam'] + df_train['Stage3 Line2 Distance Speed Collect Result_Dam'] + df_train['Stage3 Line3 Distance Speed Collect Result_Dam'] + df_train['Stage3 Line4 Distance Speed Collect Result_Dam']\n",
    "\n",
    "df_train = df_train.drop(columns=[\n",
    "                                'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
    "                                'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
    "                                'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
    "                                'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
    "                                'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
    "                                'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
    "                                'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
    "                                'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
    "                                'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
    "                                'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
    "                                'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
    "                                'Stage3 Line4 Distance Speed Collect Result_Dam',\n",
    "                                ])\n",
    "\n",
    "# 단일값이 하나인 컬럼들, 의미를 찾고싶다면 주석처리 해야하는 것들\n",
    "df_train = df_train.drop(columns=['CURE START POSITION X Collect Result_Dam', # Equipment에 따라서 정해지며, 하나로 책정됨.\n",
    "                                'CURE START POSITION Z Collect Result_Dam', # START POSITION\n",
    "                                'CURE START POSITION Θ Collect Result_Dam', # Equipment에 따라서 정해지며, 하나로 책정됨.\n",
    "                                'HEAD Standby Position X Collect Result_Dam',\n",
    "                                'HEAD Standby Position Y Collect Result_Dam',\n",
    "                                'HEAD Standby Position Z Collect Result_Dam',\n",
    "                                'Head Clean Position X Collect Result_Dam',\n",
    "                                'Head Clean Position Y Collect Result_Dam', # 흔들림에 따라 Z\n",
    "                                'Head Purge Position X Collect Result_Dam',\n",
    "                                'Head Purge Position Y Collect Result_Dam',\n",
    "                                'Head Zero Position X Collect Result_Dam',\n",
    "                                'HEAD Standby Position X Collect Result_Fill1',\n",
    "                                'HEAD Standby Position Y Collect Result_Fill1',\n",
    "                                'HEAD Standby Position Z Collect Result_Fill1',\n",
    "                                'Head Clean Position X Collect Result_Fill1',\n",
    "                                'Head Clean Position Y Collect Result_Fill1',\n",
    "                                'Head Clean Position Z Collect Result_Fill1',\n",
    "                                'Head Purge Position X Collect Result_Fill1',\n",
    "                                'Head Purge Position Y Collect Result_Fill1',\n",
    "                                'CURE END POSITION X Collect Result_Fill2',\n",
    "                                'CURE END POSITION Θ Collect Result_Fill2',\n",
    "                                'CURE STANDBY POSITION X Collect Result_Fill2',\n",
    "                                'CURE STANDBY POSITION Z Collect Result_Fill2',\n",
    "                                'CURE STANDBY POSITION Θ Collect Result_Fill2',\n",
    "                                'CURE START POSITION X Collect Result_Fill2',\n",
    "                                'CURE START POSITION Θ Collect Result_Fill2',\n",
    "                                ])\n",
    "\n",
    "# AutoClave 의미없어보이는거 제거\n",
    "df_train = df_train.drop(columns=['Chamber Temp. Collect Result_AutoClave',\n",
    "                                  'Chamber Temp. Judge Value_AutoClave',\n",
    "                                  'Chamber Temp. Unit Time_AutoClave',\n",
    "                                  '1st Pressure Collect Result_AutoClave',\n",
    "                                  '1st Pressure 1st Pressure Unit Time_AutoClave',\n",
    "                                  '2nd Pressure Collect Result_AutoClave',\n",
    "                                  '2nd Pressure Unit Time_AutoClave',\n",
    "                                  '3rd Pressure Collect Result_AutoClave',\n",
    "                                  '3rd Pressure Unit Time_AutoClave',\n",
    "                                  ])\n",
    "\n",
    "# QTY\n",
    "# df_train = df_train.drop(columns=['Production Qty Collect Result_Dam',\n",
    "#                                 'Production Qty Collect Result_Fill1',\n",
    "#                                 'Production Qty Collect Result_Fill2',\n",
    "    \n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receip 단일화\n",
    "dtype = 'string'  # 원하는 데이터 타입\n",
    "for column in ['Receip No Collect Result_Dam', 'Receip No Collect Result_Fill1', 'Receip No Collect Result_Fill2']:\n",
    "    df_train[column] = df_train[column].astype(dtype)\n",
    "    df_test[column] = df_test[column].astype(dtype)\n",
    "\n",
    "df_train['Receip No'] = df_train['Receip No Collect Result_Dam'] + df_train['Receip No Collect Result_Fill1'] + df_train['Receip No Collect Result_Fill2']\n",
    "df_test['Receip No'] = df_test['Receip No Collect Result_Dam'] + df_test['Receip No Collect Result_Fill1'] + df_test['Receip No Collect Result_Fill2']\n",
    "\n",
    "df_train = df_train.drop(columns = ['Receip No Collect Result_Dam', 'Receip No Collect Result_Fill1', 'Receip No Collect Result_Fill2'])\n",
    "df_test = df_test.drop(columns = ['Receip No Collect Result_Dam', 'Receip No Collect Result_Fill1', 'Receip No Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a33511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equipment와 PalletID 하나로 만들기\n",
    "df_train['Equipment'] = df_train['Equipment_Dam'] + df_train['Equipment_Fill1'] + df_train['Equipment_Fill2']\n",
    "df_test['Equipment'] = df_test['Equipment_Dam'] + df_test['Equipment_Fill1'] + df_test['Equipment_Fill2']\n",
    "\n",
    "df_train = df_train.drop(columns = ['Equipment_Dam', 'Equipment_Fill1', 'Equipment_Fill2'])\n",
    "df_test = df_test.drop(columns = ['Equipment_Dam', 'Equipment_Fill1', 'Equipment_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279315b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PalletID 단일화\n",
    "dtype = 'int'  # 원하는 데이터 타입\n",
    "for column in ['PalletID Collect Result_Dam', 'PalletID Collect Result_Fill1', 'PalletID Collect Result_Fill2']:\n",
    "    df_train[column] = df_train[column].astype(dtype)\n",
    "    df_test[column] = df_test[column].astype(dtype)\n",
    "    \n",
    "dtype = 'string'  # 원하는 데이터 타입\n",
    "for column in ['PalletID Collect Result_Dam', 'PalletID Collect Result_Fill1', 'PalletID Collect Result_Fill2']:\n",
    "    df_train[column] = df_train[column].astype(dtype)\n",
    "    df_test[column] = df_test[column].astype(dtype)\n",
    "    \n",
    "df_train['PalletID'] = df_train['PalletID Collect Result_Dam'] + df_train['PalletID Collect Result_Fill1']\n",
    "df_test['PalletID'] = df_test['PalletID Collect Result_Dam'] + df_test['PalletID Collect Result_Fill1']\n",
    "\n",
    "df_train = df_train.drop(columns = ['PalletID Collect Result_Dam', 'PalletID Collect Result_Fill1', 'PalletID Collect Result_Fill2'])\n",
    "df_test = df_test.drop(columns = ['PalletID Collect Result_Dam', 'PalletID Collect Result_Fill1', 'PalletID Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production QTY 단일화\n",
    "# dtype = 'string'  # 원하는 데이터 타입\n",
    "# for column in ['Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', 'Production Qty Collect Result_Fill2']:\n",
    "#     df_train[column] = df_train[column].astype(dtype)\n",
    "#     df_test[column] = df_test[column].astype(dtype)\n",
    "\n",
    "# df_train['Production Qty'] = df_train['Production Qty Collect Result_Dam'] + df_train['Production Qty Collect Result_Fill1'] + df_train['Production Qty Collect Result_Fill2']\n",
    "# df_test['Production Qty'] = df_test['Production Qty Collect Result_Dam'] + df_test['Production Qty Collect Result_Fill1'] + df_test['Production Qty Collect Result_Fill2']\n",
    "\n",
    "# df_train = df_train.drop(columns = ['Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', 'Production Qty Collect Result_Fill2'])\n",
    "# df_test = df_test.drop(columns = ['Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', 'Production Qty Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304c102",
   "metadata": {},
   "source": [
    "# Type 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "categorical_features = ['Workorder', 'Model.Suffix']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_train[feature] = le.fit_transform(df_train[feature])\n",
    "    \n",
    "    # 검증 데이터에 있는 새로운 값에 대해 처리\n",
    "    unique_values = set(df_test[feature].unique()) - set(le.classes_)\n",
    "    if unique_values:\n",
    "        # 새로운 값들을 인코딩할 무작위 숫자 생성\n",
    "        new_labels = np.random.randint(0, len(le.classes_), size=len(unique_values))\n",
    "        # 새로운 값들을 인코딩\n",
    "        le.classes_ = np.append(le.classes_, list(unique_values))\n",
    "        le.transform(list(unique_values))  # transform을 호출해서 classes_ 업데이트\n",
    "    \n",
    "    df_test[feature] = le.transform(df_test[feature])\n",
    "    label_encoders[feature] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7093fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = df_train.copy()\n",
    "cat_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train = df_train.copy()\n",
    "lgbm_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = df_train.copy()\n",
    "xgb_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a352c6",
   "metadata": {},
   "source": [
    "# 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e632bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53146ba",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ef514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Receip No Collect Result_Dam', 'Receip No Collect Result_Fill1','Receip No Collect Result_Fill2', 'PalletID Collect Result_Dam', 'PalletID Collect Result_Fill1', 'PalletID Collect Result_Fill2', 'Equipment_Dam', 'Equipment_Fill1', 'Equipment_Fill2',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d79f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['Receip No', 'Equipment', 'PalletID', 'Model.Suffix', 'Workorder']  # 변환할 컬럼명 리스트\n",
    "columns_to = ['Head Zero Position Y Collect Result_Dam',\n",
    "                'Head Zero Position Z Collect Result_Dam',\n",
    "                'Head Clean Position Z Collect Result_Dam',\n",
    "                'Head Purge Position Z Collect Result_Dam',\n",
    "                'Head Purge Position Z Collect Result_Fill1',\n",
    "                'CURE START POSITION Z Collect Result_Fill2',\n",
    "                'CURE END POSITION Z Collect Result_Fill2',\n",
    "                'CURE SPEED Collect Result_Fill2',\n",
    "                'Stage1 Circle Distance Speed_Dam',\n",
    "                'Stage2 Circle Distance Speed_Dam',\n",
    "                'Stage3 Circle Distance Speed_Dam',\n",
    "                'Stage1 Line diffent Distance Speed_Dam',\n",
    "                'Stage1 Line Sum Speed_Dam',\n",
    "                'Stage2 Line diffent Distance Speed_Dam',\n",
    "                'Stage2 Line Sum Speed_Dam',\n",
    "                'Stage3 Line diffent Distance Speed_Dam',\n",
    "                'Stage3 Line Sum Speed_Dam', 'Minus1Y_Dam', 'Minus2Y_Dam',\n",
    "                'inconsistant'\n",
    "             ]\n",
    "\n",
    "dtype = 'string'  # 원하는 데이터 타입\n",
    "for column in columns_to_convert + columns_to:\n",
    "    cat_train[column] = cat_train[column].astype(dtype)\n",
    "    cat_test[column] = cat_test[column].astype(dtype)\n",
    "    \n",
    "dtype = 'category'  # 원하는 데이터 타입\n",
    "for column in columns_to_convert + columns_to:\n",
    "    cat_train[column] = cat_train[column].astype(dtype)\n",
    "    cat_test[column] = cat_test[column].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a672249",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = cat_train.drop(columns=['target'])\n",
    "y = cat_train['target'].apply(lambda x: True if x == 'AbNormal' else False)\n",
    "\n",
    "cat_features_indices = ['Receip No', 'Equipment', 'PalletID', 'Model.Suffix', 'Workorder']  + columns_to\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_features_indices)\n",
    "valid_pool = Pool(X_valid, y_valid, cat_features=cat_features_indices)\n",
    "\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터를 샘플링\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1.0, log=True),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-2, 10.0),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-9, 10.0),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        \"od_type\": trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
    "        \"od_wait\": trial.suggest_int(\"od_wait\", 10, 50),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"verbose\": 0,\n",
    "        \"random_seed\": 42\n",
    "    }\n",
    "    \n",
    "    # CatBoost 모델 학습\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=0)\n",
    "    \n",
    "    # 검증 세트에 대한 예측 및 평가\n",
    "    preds = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, preds)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Optuna 스터디 생성 및 최적화\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=12)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb75404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 최적의 하이퍼파라미터로 모델 재학습\n",
    "cat_best_params = study.best_trial.params\n",
    "cat_best_params[\"random_seed\"] = 42\n",
    "cat_best_model = CatBoostClassifier(**cat_best_params)\n",
    "cat_best_model.fit(X_train, y_train, cat_features=cat_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f2aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 위 feature importance를 시각화해봅니다.\n",
    "importances = pd.Series(cat_best_model.feature_importances_, index=list(X_train.columns))\n",
    "importances = importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"Feature Importances\")\n",
    "sns.barplot(x=importances, y=importances.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a10a38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = cat_best_model.predict(X_valid)\n",
    "get_clf_eval(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision - Recall\n",
    "y_pred_proba = cat_best_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_pred_proba)\n",
    "f1_scores = 2*recall*precision / (recall + precision)\n",
    "cat_best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_custom_threshold = (y_pred_proba >= cat_best_threshold).astype(int)\n",
    "get_clf_eval(y_valid, y_pred_custom_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e539cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d808ec",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c48517",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['Receip No', 'Equipment', 'PalletID', 'Workorder', 'Model.Suffix']  # 변환할 컬럼명 리스트\n",
    "columns_to = ['Head Zero Position Y Collect Result_Dam',\n",
    "                'Head Zero Position Z Collect Result_Dam',\n",
    "                'Head Clean Position Z Collect Result_Dam',\n",
    "                'Head Purge Position Z Collect Result_Dam',\n",
    "                'Head Purge Position Z Collect Result_Fill1',\n",
    "                'CURE START POSITION Z Collect Result_Fill2',\n",
    "                'CURE END POSITION Z Collect Result_Fill2',\n",
    "                'CURE SPEED Collect Result_Fill2',\n",
    "                'Stage1 Circle Distance Speed_Dam',\n",
    "                'Stage2 Circle Distance Speed_Dam',\n",
    "                'Stage3 Circle Distance Speed_Dam',\n",
    "                'Stage1 Line diffent Distance Speed_Dam',\n",
    "                'Stage1 Line Sum Speed_Dam',\n",
    "                'Stage2 Line diffent Distance Speed_Dam',\n",
    "                'Stage2 Line Sum Speed_Dam',\n",
    "                'Stage3 Line diffent Distance Speed_Dam',\n",
    "                'Stage3 Line Sum Speed_Dam', 'Minus1Y_Dam', 'Minus2Y_Dam',\n",
    "                'inconsistant'\n",
    "             ]\n",
    "\n",
    "dtype = 'float'  # 원하는 데이터 타입\n",
    "for column in columns_to_convert + columns_to:\n",
    "    lgbm_train[column] = lgbm_train[column].astype(dtype)\n",
    "    lgbm_test[column] = lgbm_test[column].astype(dtype)\n",
    "    \n",
    "dtype = 'category'  # 원하는 데이터 타입\n",
    "for column in columns_to_convert + columns_to:\n",
    "    lgbm_train[column] = lgbm_train[column].astype(dtype)\n",
    "    lgbm_test[column] = lgbm_test[column].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9d45e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = lgbm_train.drop(columns=['target'])\n",
    "y = lgbm_train['target'].apply(lambda x: True if x == 'AbNormal' else False)\n",
    "\n",
    "cat_features_indices = ['Receip No', 'Equipment', 'PalletID', 'Model.Suffix', 'Workorder'] + columns_to\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    lgbm_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 400, 1500),\n",
    "        \"max_depth\": trial.suggest_int('max_depth', 3, 63),\n",
    "        \"learning_rate\": trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True), \n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        \"min_child_weight\": trial.suggest_float('min_child_weight', 0.5, 4),\n",
    "        \"min_child_samples\": trial.suggest_int('min_child_samples', 5, 100),\n",
    "        \"subsample\": trial.suggest_float('subsample', 0.4, 1),\n",
    "        \"subsample_freq\": trial.suggest_int('subsample_freq', 0, 5),\n",
    "        \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.2, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 64),\n",
    "        \"random_seed\": 42,\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**lgbm_params, device='cpu', random_state=42, verbose=-1)\n",
    "\n",
    "    # 범주형 피처 적용\n",
    "    model.fit(X_train, y_train, categorical_feature=cat_features_indices)\n",
    "\n",
    "    # 검증 데이터에서 예측 수행\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    # F1 점수 계산\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "\n",
    "    return f1\n",
    "\n",
    "# Optuna 스터디 생성 및 최적화\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best_params = study.best_trial.params\n",
    "lgbm_best_params[\"random_state\"] = 42\n",
    "lgbm_best_model = LGBMClassifier(**lgbm_best_params)\n",
    "lgbm_best_model.fit(X_train, y_train, categorical_feature=cat_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0505e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 feature importance를 시각화해봅니다.\n",
    "importances = pd.Series(lgbm_best_model.feature_importances_, index=list(X_train.columns))\n",
    "importances = importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"Feature Importances\")\n",
    "sns.barplot(x=importances, y=importances.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596eadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgbm_best_model.predict(X_valid)\n",
    "get_clf_eval(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c660c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision - Recall\n",
    "y_pred_proba = lgbm_best_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_pred_proba)\n",
    "f1_scores = 2*recall*precision / (recall + precision)\n",
    "lgbm_best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_custom_threshold = (y_pred_proba >= lgbm_best_threshold).astype(int)\n",
    "get_clf_eval(y_valid, y_pred_custom_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1bb9b",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73649493",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['Receip No', 'Equipment', 'PalletID', 'Workorder', 'Model.Suffix']  # 변환할 컬럼명 리스트\n",
    "columns_to = ['Head Zero Position Y Collect Result_Dam',\n",
    "                'Head Zero Position Z Collect Result_Dam',\n",
    "                'Head Clean Position Z Collect Result_Dam',\n",
    "                'Head Purge Position Z Collect Result_Dam',\n",
    "                'Head Purge Position Z Collect Result_Fill1',\n",
    "                'CURE START POSITION Z Collect Result_Fill2',\n",
    "                'CURE END POSITION Z Collect Result_Fill2',\n",
    "                'CURE SPEED Collect Result_Fill2',\n",
    "                'Stage1 Circle Distance Speed_Dam',\n",
    "                'Stage2 Circle Distance Speed_Dam',\n",
    "                'Stage3 Circle Distance Speed_Dam',\n",
    "                'Stage1 Line diffent Distance Speed_Dam',\n",
    "                'Stage1 Line Sum Speed_Dam',\n",
    "                'Stage2 Line diffent Distance Speed_Dam',\n",
    "                'Stage2 Line Sum Speed_Dam',\n",
    "                'Stage3 Line diffent Distance Speed_Dam',\n",
    "                'Stage3 Line Sum Speed_Dam',\n",
    "                'inconsistant'\n",
    "             ]\n",
    "\n",
    "dtype = 'float'  # 원하는 데이터 타입\n",
    "for column in columns_to_convert + columns_to:\n",
    "    xgb_train[column] = xgb_train[column].astype(dtype)\n",
    "    xgb_test[column] = xgb_test[column].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xgb_train.drop(columns=['target'])\n",
    "y = xgb_train['target'].apply(lambda x: True if x == 'AbNormal' else False)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(eval_metric='logloss', **params)\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "    \n",
    "    preds = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, preds)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Optuna 스터디 생성 및 최적화\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼파라미터로 모델 재학습\n",
    "xgb_best_params = study.best_trial.params\n",
    "xgb_best_params[\"random_state\"] = 42\n",
    "xgb_best_model = xgb.XGBClassifier(**xgb_best_params)\n",
    "xgb_best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 feature importance를 시각화해봅니다.\n",
    "importances = pd.Series(xgb_best_model.feature_importances_, index=list(X_train.columns))\n",
    "importances = importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"Feature Importances\")\n",
    "sns.barplot(x=importances, y=importances.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35cee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = xgb_best_model.predict(X_valid)\n",
    "get_clf_eval(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fae8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision - Recall\n",
    "\n",
    "y_pred_proba = xgb_best_model.predict_proba(X_valid)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_pred_proba)\n",
    "f1_scores = 2*recall*precision / (recall + precision)\n",
    "xgb_best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_custom_threshold = (y_pred_proba >= xgb_best_threshold).astype(int)\n",
    "get_clf_eval(y_valid, y_pred_custom_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b62805",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c728cb2",
   "metadata": {},
   "source": [
    "### Voting 실험?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1_2 = proba1 + proba2 / 2\n",
    "y_1_3 = proba1 + proba3 / 2\n",
    "y_2_3 = proba2 + proba3 / 2\n",
    "y_1_2_3 = proba1 + proba2 + proba3 / 3\n",
    "# y_1_2_3_4 = proba1 + proba2 + proba3 + proba4 / 4\n",
    "# y_1_2_3_4_5 = proba1 + proba2 + proba3 + proba4 + proba5 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_1_2)\n",
    "f1_scores = 2*recall*precision / (recall + precision)\n",
    "best_threshold_1 = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_custom_threshold_1 = (y_1_2 >= best_threshold_1).astype(int)\n",
    "get_clf_eval(y_valid, y_pred_custom_threshold_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_1_3)\n",
    "f1_scores = 2*recall*precision / (recall + precision)\n",
    "best_threshold_2 = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_custom_threshold = (y_1_3 >= best_threshold_2).astype(int)\n",
    "get_clf_eval(y_valid, y_pred_custom_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de05175",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_2_3)\n",
    "f1_scores = 2*recall*precision / (recall + precision)\n",
    "best_threshold_3 = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_custom_threshold = (y_2_3 >= best_threshold_3).astype(int)\n",
    "get_clf_eval(y_valid, y_pred_custom_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82223ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_1_2_3)\n",
    "f1_scores = 2*recall*precision / (recall + precision)\n",
    "best_threshold_4 = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_custom_threshold = (y_1_2_3 >= best_threshold_4).astype(int)\n",
    "get_clf_eval(y_valid, y_pred_custom_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2b5f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "best_f1_t = 0\n",
    "best_weights = None\n",
    "best_weights_t = None\n",
    "\n",
    "# 가중치 조합 테스트\n",
    "for w1 in range(1, 15):\n",
    "    for w2 in range(0, 15):\n",
    "        for w3 in range(0, 30):\n",
    "                # 가중 평균 계산\n",
    "                final_proba = (w1 * proba1 + w2 * proba2 + w3 * proba3) / (w1 + w2 + w3)\n",
    "                y_pred = (final_proba > 0.5).astype(int)\n",
    "            \n",
    "                # F1 스코어 계산\n",
    "                f1 = f1_score(y_valid, y_pred)\n",
    "                print(f1)\n",
    "                \n",
    "                # Threshold 스코어 계산\n",
    "                precision, recall, thresholds = precision_recall_curve(y_valid, final_proba)\n",
    "                f1_scores = 2*recall*precision / (recall + precision)\n",
    "                best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "                y_pred_custom_threshold = (final_proba >= best_threshold).astype(int)\n",
    "                f1_t = f1_score(y_valid, y_pred_custom_threshold)\n",
    "                print(f1_t)\n",
    "                \n",
    "                # 최고 성능 저장\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_weights = (w1, w2, w3)\n",
    "                \n",
    "                if f1_t > best_f1_t:\n",
    "                    best_f1_t = f1_t\n",
    "                    best_weights_t = (w1, w2, w3)\n",
    "\n",
    "print(\"Best F1 Score: \", best_f1)\n",
    "print(\"Best Weights: \", best_weights)\n",
    "print(\"Best F1_t Score: \", best_f1_t)\n",
    "print(\"Best Weights_t: \", best_weights_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58464ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_best = (best_weights_t[0] * proba1 + best_weights_t[1] * proba2 + best_weights_t[2] * proba3) / (best_weights_t[0] + best_weights_t[1] + best_weights_t[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eaab5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_best)\n",
    "f1_scores = 2*recall*precision / (recall + precision)\n",
    "weights_best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_custom_threshold = (y_best >= weights_best_threshold).astype(int)\n",
    "get_clf_eval(y_valid, y_pred_custom_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5caa91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights_best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a46bf",
   "metadata": {},
   "source": [
    "# 학습 후 예측 및 제출용 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e433b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_id = pd.read_csv('test_df.csv')\n",
    "cat_test = pd.concat([cat_test, set_id['Set ID']], axis = 1)\n",
    "xgb_test = pd.concat([xgb_test, set_id['Set ID']], axis = 1)\n",
    "lgbm_test = pd.concat([lgbm_test, set_id['Set ID']], axis = 1)\n",
    "# extra_test = pd.concat([extra_test, set_id['Set ID']], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4341ca",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d9c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_pred = cat_best_model.predict(cat_test.drop(columns='Set ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef963c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cat_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8663126",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pred_proba = cat_best_model.predict_proba(cat_test.drop(columns='Set ID'))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cat = (cat_pred_proba >= cat_best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32583f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8ecc91",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe551774",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred = lgbm_best_model.predict(lgbm_test.drop(columns='Set ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lgbm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc29805",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred_proba = lgbm_best_model.predict_proba(lgbm_test.drop(columns='Set ID'))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446854a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgbm = (lgbm_pred_proba >= lgbm_best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc94a1b",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7550a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = xgb_best_model.predict(xgb_test.drop(columns='Set ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbfd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred_proba = xgb_best_model.predict_proba(xgb_test.drop(columns='Set ID'))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = (xgb_pred_proba >= best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b26ff2d",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = (cat_pred_proba * 1 + lgbm_pred_proba * 11 + xgb_pred_proba * 4) / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acddcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_custom_threshold = (y_result >= weights_best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750db1c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(y_pred_custom_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5b99d",
   "metadata": {},
   "source": [
    "### 데이터 결정 및 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = y_pred_custom_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98dfbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(result == 0, \"Normal\", \"AbNormal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = y_pred\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
